import torch
import torch.nn as nn
import torch.optim as optim
from torch.optim.lr_scheduler import ExponentialLR
import numpy as np
import os
from simulator import Simulator
from label_utils import create_evaluation_regions_mode_wavelength, evaluate_output, evaluate_all_regions

device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')

class Trainer:
    def __init__(self, config, data_generator, model_class, evaluation_regions=None):
        self.config = config
        self.data_generator = data_generator
        self.model_class = model_class
        
        # ä½¿ç”¨æä¾›çš„è¯„ä¼°åŒºåŸŸæˆ–åˆ›å»ºæ–°çš„åŒºåŸŸ
        if evaluation_regions is not None:
            self.evaluation_regions = evaluation_regions
            print(f"ä½¿ç”¨å¤–éƒ¨æä¾›çš„è¯„ä¼°åŒºåŸŸ: {len(evaluation_regions)}ä¸ªåŒºåŸŸ")
        else:
            # ä½¿ç”¨æ–°çš„åˆ›å»ºæ–¹æ³•
            self.evaluation_regions = create_evaluation_regions_mode_wavelength(
                self.config.layer_size,
                self.config.layer_size,
                self.config.focus_radius,
                detectsize=self.config.detectsize
            )
            print(f"åˆ›å»ºè¯„ä¼°åŒºåŸŸ: {len(self.evaluation_regions)}ä¸ªåŒºåŸŸ")

    def train_model(self, num_layers):
        train_loader = self.data_generator.create_dataloader()
        model = self.model_class(self.config, num_layers).to(device)
        losses = self._train_loop(model, train_loader)
        evaluation_results = self._evaluate_model(model, train_loader)
        
        # ä¿å­˜è®­ç»ƒç»“æœ
        self._save_training_results(model, losses, num_layers)
        
        return {
            'models': model,
            'losses': losses,
            'phase_masks': self._extract_phase_masks(model),
            'weights_pred': evaluation_results['weights_pred'],
            'visibility': evaluation_results['visibility']
        }

    def _save_training_results(self, model, losses, num_layers):
        """ä¿å­˜è®­ç»ƒç»“æœ"""
        # åˆ›å»ºä¿å­˜ç›®å½•
        save_dir = os.path.join(self.config.save_dir, "trained_models")
        os.makedirs(save_dir, exist_ok=True)
        
        # ä¿å­˜å®Œæ•´æ¨¡å‹
        model_path = os.path.join(save_dir, f"trained_model_{num_layers}layers.pth")
        torch.save({
            'model_state_dict': model.state_dict(),
            'model_config': {
                'num_layers': num_layers,
                'model_class': self.model_class.__name__
            },
            'train_losses': losses,
            'config': self.config.__dict__ if hasattr(self.config, '__dict__') else {}
        }, model_path)
        print(f"âœ“ å®Œæ•´æ¨¡å‹å·²ä¿å­˜åˆ°: {model_path}")
        
        # ä¿å­˜ç›¸ä½æ©ç ï¼ˆç”¨äºä»¿çœŸï¼‰
        masks_path = os.path.join(save_dir, f"trained_phase_masks_{num_layers}layers.npz")
        model.save_trained_masks(masks_path)
        
        # ä¿å­˜è®­ç»ƒæŸå¤±æ›²çº¿
        loss_path = os.path.join(save_dir, f"training_losses_{num_layers}layers.npy")
        np.save(loss_path, losses)
        print(f"âœ“ è®­ç»ƒæŸå¤±å·²ä¿å­˜åˆ°: {loss_path}")
        
        # ä¿å­˜ç›¸ä½æ©ç å¯è§†åŒ–
        vis_dir = os.path.join(save_dir, f"phase_mask_visualization_{num_layers}layers")
        model.print_phase_masks(save_path=vis_dir)
        
        return model_path, masks_path

    def _train_loop(self, model, train_loader):
        criterion = nn.MSELoss()
        optimizer = optim.Adam(model.parameters(), lr=self.config.learning_rate)
        scheduler = ExponentialLR(optimizer, gamma=self.config.lr_decay)
        losses = []
        
        print(f"å¼€å§‹è®­ç»ƒ - è®¾å¤‡: {device}")
        print(f"è®­ç»ƒå‚æ•°: epochs={self.config.epochs}, lr={self.config.learning_rate}")
        
        for epoch in range(self.config.epochs):
            model.train()
            epoch_loss = 0
            for batch_idx, (images, labels) in enumerate(train_loader):
                images = images.to(device, dtype=torch.complex64)
                labels = labels.to(device)  # ä¿æŒæ ‡ç­¾åŸæ ·
                
                optimizer.zero_grad()
                outputs = model(images)
                
                # åŠ¨æ€é€‚åº”æ ‡ç­¾é€šé“æ•°
                label_channels = labels.shape[1]
                loss = criterion(outputs[:, :label_channels], labels)
                loss.backward()
                optimizer.step()
                epoch_loss += loss.item()
            
            scheduler.step()
            avg_loss = epoch_loss / len(train_loader)
            losses.append(avg_loss)
            
            if epoch % 100 == 0:
                print(f'Epoch [{epoch}/{self.config.epochs}], Loss: {avg_loss:.18f}')
        
        print("âœ“ è®­ç»ƒå®Œæˆ!")
        return losses

    def _extract_phase_masks(self, model):
        """æå–ç›¸ä½æ©ç ç”¨äºè¿”å›"""
        if hasattr(model, 'get_phase_masks_for_simulation'):
            return model.get_phase_masks_for_simulation()
        else:
            # å…¼å®¹æ—§ç‰ˆæœ¬
            phase_masks = []
            for layer in model.layers:
                # è·å–å•ä¸ªç›¸ä½æ©è†œ
                phase = layer.phase.detach().cpu().numpy()
                phase = phase % (2 * np.pi)
                
                wavelength_masks = []
                for _ in range(len(self.config.wavelengths)):
                    wavelength_masks.append(phase)
                phase_masks.append(wavelength_masks)
            return phase_masks

    def _evaluate_model(self, model, test_loader):
        model.eval()
        all_weights_pred = []
        with torch.no_grad():
            for images, labels in test_loader:
                images = images.to(device, dtype=torch.complex64)
                predictions = model(images)
                B, C, H, W = predictions.shape
                
                # ç¡®ä¿Cç­‰äºæ³¢é•¿æ•°é‡
                if C != len(self.config.wavelengths):
                    print(f"è­¦å‘Š: é¢„æµ‹é€šé“æ•°({C})ä¸æ³¢é•¿æ•°é‡({len(self.config.wavelengths)})ä¸åŒ¹é…")
                
                # å¤„ç†æ¯ä¸ªæ³¢é•¿çš„é¢„æµ‹
                weights_batch = []
                for c in range(min(C, len(self.config.wavelengths))):
                    chan = predictions[:, c]
                    energies = []
                    # ä½¿ç”¨æ‰€æœ‰è¯„ä¼°åŒºåŸŸ
                    for region_idx, region in enumerate(self.evaluation_regions):
                        xs, xe, ys, ye = region
                        region_sum = chan[:, ys:ye, xs:xe].sum(dim=(-2, -1))
                        energies.append(region_sum)
                    energies = torch.stack(energies, dim=1)
                    weights_batch.append(energies)
                
                # é‡æ–°æ’åˆ—ç»´åº¦: [æ³¢é•¿, æ‰¹æ¬¡, è¯„ä¼°åŒºåŸŸ]
                weights_batch = torch.stack(weights_batch, dim=0)
                all_weights_pred.append(weights_batch.cpu())
        
        # åˆå¹¶æ‰¹æ¬¡ç»´åº¦
        weights_pred = torch.cat(all_weights_pred, dim=1).numpy()
        
        # è®¡ç®—å¯è§åº¦ - ä¿®å¤ä¸ºæ¯ä¸ªæ³¢é•¿æ¯ä¸ªæ¨¡å¼çš„å¯è§åº¦
        visibility = self._calculate_visibility_fixed(weights_pred)
        
        return {'weights_pred': weights_pred, 'visibility': visibility}

    def _calculate_visibility_fixed(self, weights):
        """
        ä¿®å¤ç‰ˆæœ¬ï¼šè¿”å›æ¯ä¸ªæ³¢é•¿æ¯ä¸ªæ¨¡å¼çš„å¯è§åº¦
        è¿”å›æ ¼å¼ï¼š[wl1_mode1, wl1_mode2, wl1_mode3, wl2_mode1, wl2_mode2, wl2_mode3, wl3_mode1, wl3_mode2, wl3_mode3]
        """
        if torch.is_tensor(weights):
            weights = weights.cpu().numpy()
        
        num_wavelengths, num_batches, num_regions = weights.shape
        num_modes = self.config.num_modes
        
        print(f"è®¡ç®—å¯è§åº¦: {num_wavelengths}æ³¢é•¿, {num_batches}æ‰¹æ¬¡, {num_regions}åŒºåŸŸ, {num_modes}æ¨¡å¼")
        
        # å­˜å‚¨æ¯ä¸ªæ³¢é•¿æ¯ä¸ªæ¨¡å¼çš„å¯è§åº¦
        all_visibilities = []
        
        # å¯¹æ¯ä¸ªæ³¢é•¿åˆ†åˆ«è®¡ç®—
        for wl_idx in range(num_wavelengths):
            wavelength = self.config.wavelengths[wl_idx]
            print(f"å¤„ç†æ³¢é•¿ {wavelength*1e9:.0f}nm (ç´¢å¼•{wl_idx})")
            
            # å¯¹è¯¥æ³¢é•¿ä¸‹çš„æ¯ä¸ªæ¨¡å¼è®¡ç®—å¯è§åº¦
            for mode_idx in range(num_modes):
                print(f"  å¤„ç†æ¨¡å¼ {mode_idx+1}")
                
                # è®¡ç®—è¯¥æ³¢é•¿è¯¥æ¨¡å¼åœ¨æ‰€æœ‰æ‰¹æ¬¡ä¸­çš„å¯è§åº¦
                mode_vis_across_batches = []
                
                for batch_idx in range(num_batches):
                    # æ‰¾å‡ºè¯¥æ¨¡å¼å¯¹åº”çš„åŒºåŸŸç´¢å¼•
                    # å‡è®¾åŒºåŸŸæŒ‰ [mode0_wl0, mode1_wl0, mode2_wl0, mode0_wl1, mode1_wl1, mode2_wl1, ...] æ’åˆ—
                    # æˆ–è€…æŒ‰ [mode0_wl0, mode0_wl1, mode0_wl2, mode1_wl0, mode1_wl1, mode1_wl2, ...] æ’åˆ—
                    
                    # æ”¶é›†è¯¥æ¨¡å¼åœ¨è¯¥æ³¢é•¿ä¸‹çš„æ‰€æœ‰ç›¸å…³åŒºåŸŸèƒ½é‡
                    mode_energies = []
                    
                    # æ–¹æ³•1ï¼šå‡è®¾åŒºåŸŸæŒ‰æ¨¡å¼ä¼˜å…ˆæ’åˆ— (mode0_all_wl, mode1_all_wl, mode2_all_wl)
                    regions_per_mode = num_regions // num_modes
                    start_region = mode_idx * regions_per_mode
                    end_region = (mode_idx + 1) * regions_per_mode
                    
                    # åœ¨è¯¥æ¨¡å¼çš„åŒºåŸŸèŒƒå›´å†…ï¼Œæ‰¾åˆ°å¯¹åº”å½“å‰æ³¢é•¿çš„åŒºåŸŸ
                    for region_idx in range(start_region, min(end_region, num_regions)):
                        energy = weights[wl_idx, batch_idx, region_idx]
                        mode_energies.append(energy)
                    
                    # å¦‚æœä¸Šé¢çš„æ–¹æ³•ä¸å¯¹ï¼Œå°è¯•æ–¹æ³•2ï¼šåŒºåŸŸæŒ‰æ³¢é•¿ä¼˜å…ˆæ’åˆ—
                    if not mode_energies or len(mode_energies) < 3:  # æ¯ä¸ªæ¨¡å¼åº”è¯¥è‡³å°‘æœ‰3ä¸ªæ£€æµ‹å™¨
                        mode_energies = []
                        # å‡è®¾æ¯ä¸ªæ³¢é•¿æœ‰ num_modes*3 ä¸ªåŒºåŸŸï¼ˆæ¯ä¸ªæ¨¡å¼3ä¸ªæ£€æµ‹å™¨ï¼‰
                        regions_per_wavelength = num_modes * 3
                        detector_start = mode_idx * 3
                        detector_end = detector_start + 3
                        
                        for detector_idx in range(detector_start, detector_end):
                            if detector_idx < num_regions:
                                energy = weights[wl_idx, batch_idx, detector_idx]
                                mode_energies.append(energy)
                    
                    # è®¡ç®—è¯¥æ‰¹æ¬¡è¯¥æ¨¡å¼çš„å¯è§åº¦
                    if len(mode_energies) >= 2:  # è‡³å°‘éœ€è¦2ä¸ªæ£€æµ‹å™¨æ¥è®¡ç®—å¯è§åº¦
                        I_max = np.max(mode_energies)
                        I_min = np.min(mode_energies)
                        
                        if I_max + I_min > 1e-12:
                            visibility = (I_max - I_min) / (I_max + I_min)
                        else:
                            visibility = 0.0
                    else:
                        visibility = 0.0
                    
                    mode_vis_across_batches.append(visibility)
                    
                    if batch_idx == 0:  # åªæ‰“å°ç¬¬ä¸€ä¸ªæ‰¹æ¬¡çš„è¯¦ç»†ä¿¡æ¯
                        print(f"    æ‰¹æ¬¡0: èƒ½é‡={mode_energies}, å¯è§åº¦={visibility:.6f}")
                
                # è®¡ç®—è¯¥æ³¢é•¿è¯¥æ¨¡å¼æ‰€æœ‰æ‰¹æ¬¡çš„å¹³å‡å¯è§åº¦
                if mode_vis_across_batches:
                    avg_visibility = np.mean(mode_vis_across_batches)
                    all_visibilities.append(avg_visibility)
                    print(f"  æ¨¡å¼{mode_idx+1}å¹³å‡å¯è§åº¦: {avg_visibility:.6f}")
                else:
                    all_visibilities.append(0.0)
                    print(f"  æ¨¡å¼{mode_idx+1}å¹³å‡å¯è§åº¦: 0.0 (æ— æœ‰æ•ˆæ•°æ®)")
        
        print(f"æ€»å…±è®¡ç®—äº† {len(all_visibilities)} ä¸ªå¯è§åº¦å€¼")
        print(f"æœŸæœ›å€¼: {num_wavelengths * num_modes}")
        
        return all_visibilities

    def train_multiple_models(self, num_layer_options):
        results = {'models': [], 'losses': [], 'phase_masks': [], 'weights_pred': [], 'visibility': []}
        
        for num_layers in num_layer_options:
            print(f"\n{'='*50}")
            print(f"å¼€å§‹è®­ç»ƒ {num_layers} å±‚æ¨¡å‹...")
            print(f"{'='*50}")
            
            model_result = self.train_model(num_layers)
            
            # æ”¶é›†æ¯ä¸ªå±‚æ•°ä¸‹çš„æ¨¡å‹ç»“æœ
            for k in results:
                results[k].append(model_result[k])
            
            print(f"âœ“ {num_layers}å±‚æ¨¡å‹è®­ç»ƒå®Œæˆï¼Œå¯è§åº¦æ•°é‡: {len(model_result['visibility'])}")
            
        return results

    @staticmethod
    def load_trained_model(model_path, model_class, config):
        """åŠ è½½è®­ç»ƒå¥½çš„å®Œæ•´æ¨¡å‹"""
        try:
            checkpoint = torch.load(model_path, map_location=device)
            
            # è·å–æ¨¡å‹é…ç½®
            model_config = checkpoint.get('model_config', {})
            num_layers = model_config.get('num_layers', 3)
            
            # åˆ›å»ºæ¨¡å‹å®ä¾‹
            model = model_class(config, num_layers).to(device)
            
            # åŠ è½½æ¨¡å‹å‚æ•°
            model.load_state_dict(checkpoint['model_state_dict'])
            
            print(f"âœ“ æˆåŠŸåŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹: {model_path}")
            print(f"  æ¨¡å‹ç±»å‹: {model_config.get('model_class', 'Unknown')}")
            print(f"  å±‚æ•°: {num_layers}")
            
            return model, checkpoint.get('train_losses', [])
            
        except Exception as e:
            print(f"âœ— åŠ è½½æ¨¡å‹å¤±è´¥: {e}")
            return None, None

    def evaluate_model_with_cross_matrix(self, model, test_inputs, layer_count):
        """
        ä½¿ç”¨äº¤å‰çŸ©é˜µå’ŒSNRè¯„ä¼°æ¨¡å‹
        """
        model.eval()
        with torch.no_grad():
            # è·å–ç›¸ä½æ©è†œ
            phase_masks = []
            for layer in model.layers:
                if hasattr(layer, 'phase_mask'):
                    phase_masks.append(layer.phase_mask.detach())
            
            # åˆ›å»ºæ¨¡æ‹Ÿå™¨
            simulator = Simulator(
                self.config.H, self.config.W, self.config.dx,
                self.config.wavelengths, self.config.propagation_distance,
                phase_masks, self.config.target_positions
            )
            
            # è¿è¡Œæ¨¡æ‹Ÿ
            outputs = []
            for mode_idx in range(self.config.num_modes):
                mode_input = test_inputs[mode_idx:mode_idx+1]  # [1, num_wl, H, W]
                mode_output = simulator(mode_input)  # [1, num_wl, H, W]
                outputs.append(mode_output[0])  # [num_wl, H, W]
            
            outputs = torch.stack(outputs)  # [num_modes, num_wl, H, W]
            
            # è®¡ç®—äº¤å‰çŸ©é˜µå’ŒSNR
            cross_matrix, snr_matrix, focus_metrics = calculate_cross_matrix_and_snr(
                outputs, self.config.target_positions, radius=self.config.focus_radius
            )
            
            # æ‰“å°åˆ†æç»“æœ
            separation_quality, avg_snrs = print_cross_matrix_analysis(
                cross_matrix, snr_matrix, focus_metrics, self.config.wavelengths
            )
            
            return {
                'cross_matrix': cross_matrix,
                'snr_matrix': snr_matrix,
                'focus_metrics': focus_metrics,
                'separation_quality': separation_quality,
                'avg_snrs': avg_snrs,
                'outputs': outputs
            }

    def train_single_configuration(self, num_layers):
        """
        ä¿®æ”¹åçš„è®­ç»ƒå‡½æ•°ï¼Œä½¿ç”¨æ–°çš„è¯„ä¼°æ–¹æ³•
        """
        # ... åŸæœ‰çš„è®­ç»ƒä»£ç  ...
        
        # è®­ç»ƒå®Œæˆåçš„è¯„ä¼°
        print(f"\nğŸ” è¯„ä¼° {num_layers} å±‚æ¨¡å‹...")
        evaluation_results = self.evaluate_model_with_cross_matrix(model, test_inputs, num_layers)
        
        # ä¿å­˜ç»“æœ
        results = {
            'num_layers': num_layers,
            'cross_matrix': evaluation_results['cross_matrix'],
            'snr_matrix': evaluation_results['snr_matrix'],
            'separation_quality': evaluation_results['separation_quality'],
            'avg_snrs': evaluation_results['avg_snrs'],
            'focus_metrics': evaluation_results['focus_metrics']
        }
        
        return model, results


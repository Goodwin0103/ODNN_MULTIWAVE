{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9bbba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "多模式多波长光场调制系统 - 主程序（修改版）\n",
    "集成训练-仿真工作流程 - 无需额外模块版本\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "# 导入自定义模块\n",
    "from label_utils import create_evaluation_regions_mode_wavelength, evaluate_output, evaluate_all_regions, visualize_labels\n",
    "from config import Config\n",
    "from data_generator import MultiModeMultiWavelengthDataGenerator\n",
    "from visualizer import Visualizer\n",
    "from trainer import Trainer\n",
    "from model import MultiModeMultiWavelengthModel\n",
    "from simulator import Simulator\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# 设置随机种子，确保结果可重现\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"多模式多波长光场调制系统 - 训练-仿真集成版\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ===== 掩码加载器类（内联定义）=====\n",
    "class SimpleMaskLoader:\n",
    "    \"\"\"简化的相位掩码加载器\"\"\"\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "    \n",
    "    def create_fallback_masks(self, num_layers=3):\n",
    "        \"\"\"创建备用聚焦掩码\"\"\"\n",
    "        print(\"⚠ 创建备用聚焦掩码...\")\n",
    "        \n",
    "        def create_focusing_mask(size, wavelength, focal_length, pixel_size):\n",
    "            center = size // 2\n",
    "            y, x = np.ogrid[:size, :size]\n",
    "            r_squared = ((x - center) * pixel_size) ** 2 + ((y - center) * pixel_size) ** 2\n",
    "            k = 2 * np.pi / wavelength\n",
    "            phase = -k * r_squared / (2 * focal_length)\n",
    "            return np.mod(phase, 2 * np.pi)\n",
    "        \n",
    "        masks = []\n",
    "        focal_lengths = [50e-3, 100e-3, 150e-3]  # 不同层的焦距\n",
    "        \n",
    "        for layer_idx in range(num_layers):\n",
    "            layer_masks = []\n",
    "            for wl_idx, wavelength in enumerate(self.config.wavelengths):\n",
    "                focal_length = focal_lengths[layer_idx % len(focal_lengths)]\n",
    "                mask = create_focusing_mask(\n",
    "                    self.config.layer_size, wavelength, focal_length, self.config.pixel_size\n",
    "                )\n",
    "                layer_masks.append(mask)\n",
    "            masks.append(layer_masks)\n",
    "        \n",
    "        print(f\"✓ 创建了 {len(masks)} 层备用掩码\")\n",
    "        return masks\n",
    "    \n",
    "    def get_masks_for_simulation(self, trained_masks=None, num_layers=3):\n",
    "        \"\"\"获取用于仿真的掩码\"\"\"\n",
    "        if trained_masks is not None:\n",
    "            print(\"✓ 使用训练好的相位掩码进行仿真\")\n",
    "            return trained_masks\n",
    "        else:\n",
    "            print(\"⚠ 使用备用掩码进行仿真\")\n",
    "            return self.create_fallback_masks(num_layers)\n",
    "\n",
    "# 创建配置\n",
    "config = Config(\n",
    "    # 基本参数\n",
    "    num_modes=3,                                # 模式数量\n",
    "    wavelengths=np.array([450e-9, 550e-9, 650e-9]),  # 波长列表(m)\n",
    "    \n",
    "    # 空间参数\n",
    "    field_size=50,                              # 场大小(像素)\n",
    "    layer_size=200,                             # 层大小(像素)\n",
    "    focus_radius=5,                             # 焦点半径(像素)\n",
    "    detectsize=15,                              # 检测区域大小(像素)\n",
    "    \n",
    "    # 物理参数\n",
    "    z_layers=40e-6,                             # 层间距离(m)\n",
    "    z_prop=300e-6,                              # 传播距离(m)\n",
    "    z_step=20e-6,                               # 传播步长(m)\n",
    "    pixel_size=1e-6,                            # 像素大小(m)\n",
    "    \n",
    "    # 检测区域偏移 - 为每个波长定义不同的偏移\n",
    "    offsets=[(0,0), (0,0), (0,0)],           # 每个波长的检测区域偏移\n",
    "    \n",
    "    # 训练参数\n",
    "    learning_rate=0.01,                         # 学习率\n",
    "    lr_decay=0.99,                              # 学习率衰减\n",
    "    epochs=700,                                 # 训练轮数\n",
    "    batch_size=16,                               # 批量大小\n",
    "    \n",
    "    # 保存参数\n",
    "    save_dir=\"./results_multi_mode_multi_wl/\",  # 保存目录\n",
    "    flag_savemat=True                           # 是否保存.mat文件\n",
    ")\n",
    "\n",
    "# 确保保存目录存在\n",
    "os.makedirs(config.save_dir, exist_ok=True)\n",
    "os.makedirs(os.path.join(config.save_dir, \"trained_models\"), exist_ok=True)\n",
    "\n",
    "# ===== 阶段1: 数据准备 =====\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"阶段1: 数据准备\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# 创建数据生成器\n",
    "print(\"创建数据生成器...\")\n",
    "data_generator = MultiModeMultiWavelengthDataGenerator(config)\n",
    "\n",
    "# 生成多模式多波长标签\n",
    "print(\"生成标签...\")\n",
    "labels = data_generator.generate_labels()\n",
    "\n",
    "# 可视化标签布局\n",
    "print(\"可视化标签布局...\")\n",
    "visualize_labels(labels, config.wavelengths)\n",
    "\n",
    "# 创建评估区域\n",
    "print(\"创建评估区域...\")\n",
    "# 在您的主程序中，创建evaluation_regions时也要传入偏移\n",
    "evaluation_regions = create_evaluation_regions_mode_wavelength(\n",
    "    config.layer_size, \n",
    "    config.layer_size, \n",
    "    config.focus_radius, \n",
    "    detectsize=config.detectsize,\n",
    "    offsets=config.offsets  # ← 添加偏移参数\n",
    ")\n",
    "\n",
    "print(\"✓ 数据准备完成\")\n",
    "\n",
    "# ===== 阶段2: 模型训练 =====\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"阶段2: 模型训练\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# 检查是否存在已训练的模型\n",
    "trained_models_dir = os.path.join(config.save_dir, \"trained_models\")\n",
    "existing_models = []\n",
    "if os.path.exists(trained_models_dir):\n",
    "    model_files = [f for f in os.listdir(trained_models_dir) if f.startswith(\"model_\") and f.endswith(\"layers.pth\")]\n",
    "    existing_models = [f for f in model_files]\n",
    "\n",
    "# 定义要训练的层数选项\n",
    "num_layer_options = [1, 2, 3, 4, 5]  # 可以根据需要调整层数\n",
    "\n",
    "# 询问是否使用现有模型或重新训练\n",
    "use_existing = False\n",
    "if existing_models:\n",
    "    print(f\"发现已存在的训练模型: {existing_models}\")\n",
    "    try:\n",
    "        response = input(\"是否使用现有模型？(y/n，默认n): \").lower().strip()\n",
    "        use_existing = response == 'y'\n",
    "    except:\n",
    "        print(\"使用默认选项：重新训练\")\n",
    "        use_existing = False\n",
    "\n",
    "if use_existing and existing_models:\n",
    "    print(\"加载现有训练模型...\")\n",
    "    results = {'models': [], 'losses': [], 'phase_masks': [], 'weights_pred': [], 'visibility': []}\n",
    "    \n",
    "    for num_layers in num_layer_options:\n",
    "        model_path = os.path.join(trained_models_dir, f\"model_{num_layers}layers.pth\")\n",
    "        if os.path.exists(model_path):\n",
    "            print(f\"加载 {num_layers} 层模型...\")\n",
    "            \n",
    "            try:\n",
    "                # 加载模型检查点\n",
    "                checkpoint = torch.load(model_path, map_location='cpu')\n",
    "                \n",
    "                # 创建模型实例\n",
    "                model = MultiModeMultiWavelengthModel(config, num_layers)\n",
    "                model.load_state_dict(checkpoint['model_state_dict'])\n",
    "                \n",
    "                # 提取相位掩码\n",
    "                phase_masks = []\n",
    "                if hasattr(model, 'get_phase_masks_for_simulation'):\n",
    "                    phase_masks = model.get_phase_masks_for_simulation()\n",
    "                else:\n",
    "                    # 兼容旧版本\n",
    "                    for layer in model.layers:\n",
    "                        phase = layer.phase.detach().cpu().numpy()\n",
    "                        phase = phase % (2 * np.pi)\n",
    "                        wavelength_masks = []\n",
    "                        for _ in range(len(config.wavelengths)):\n",
    "                            wavelength_masks.append(phase)\n",
    "                        phase_masks.append(wavelength_masks)\n",
    "                \n",
    "                # 获取训练损失和可见度\n",
    "                losses = checkpoint.get('train_losses', [])\n",
    "                weights_pred = checkpoint.get('weights_pred', [])\n",
    "                visibility = checkpoint.get('visibility', [])\n",
    "\n",
    "                \n",
    "                results['models'].append(model)\n",
    "                results['losses'].append(losses)\n",
    "                results['phase_masks'].append(phase_masks)\n",
    "                results['weights_pred'].append(weights_pred)\n",
    "                results['visibility'].append(visibility)\n",
    "                \n",
    "                \n",
    "                print(f\"✓ 成功加载 {num_layers} 层模型\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"✗ 加载 {num_layers} 层模型失败: {e}\")\n",
    "                # 添加空结果以保持索引一致\n",
    "                results['models'].append(None)\n",
    "                results['losses'].append([])\n",
    "                results['phase_masks'].append([])\n",
    "                results['weights_pred'].append([])\n",
    "                results['visibility'].append([])\n",
    "        else:\n",
    "            print(f\"✗ 未找到 {num_layers} 层模型文件\")\n",
    "            # 添加空结果以保持索引一致\n",
    "            results['models'].append(None)\n",
    "            results['losses'].append([])\n",
    "            results['phase_masks'].append([])\n",
    "            results['weights_pred'].append([])\n",
    "            results['visibility'].append([])\n",
    "else:\n",
    "    print(\"开始训练新模型...\")\n",
    "    \n",
    "    # 创建训练器\n",
    "    trainer = Trainer(config, data_generator, MultiModeMultiWavelengthModel, evaluation_regions=evaluation_regions)\n",
    "    \n",
    "    # 训练多个层数的模型\n",
    "    results = trainer.train_multiple_models(num_layer_options)\n",
    "\n",
    "print(\"✓ 模型准备完成\")\n",
    "\n",
    "\n",
    "\n",
    "# ===== 阶段3: 结果分析 =====\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"阶段3: 结果分析\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# 检查可见度数据结构\n",
    "print(\"检查训练结果...\")\n",
    "print(f\"results键: {list(results.keys())}\")\n",
    "print(f\"可见度数据结构: {len(results['visibility'])}层\")\n",
    "\n",
    "valid_results = []\n",
    "for i, vis_data in enumerate(results['visibility']):\n",
    "    if vis_data:  # 只处理非空的可见度数据\n",
    "        expected_length = len(config.wavelengths) * config.num_modes\n",
    "        print(f\"第{i+1}层 ({num_layer_options[i]}层模型):\")\n",
    "        print(f\"  数据长度: {len(vis_data)}\")\n",
    "        print(f\"  期望长度: {expected_length} ({len(config.wavelengths)}波长 × {config.num_modes}模式)\")\n",
    "        \n",
    "        if len(vis_data) == expected_length:\n",
    "            print(f\"  ✅ 数据长度匹配！\")\n",
    "            valid_results.append(i)\n",
    "            # 按波长和模式重新组织显示\n",
    "            vis_array = np.array(vis_data).reshape(len(config.wavelengths), config.num_modes)\n",
    "            for wl_idx, wl in enumerate(config.wavelengths):\n",
    "                wl_nm = wl * 1e9\n",
    "                print(f\"    {wl_nm:.0f}nm: MODE1={vis_array[wl_idx, 0]:.6f}, MODE2={vis_array[wl_idx, 1]:.6f}, MODE3={vis_array[wl_idx, 2]:.6f}\")\n",
    "        else:\n",
    "            print(f\"  ❌ 数据长度不匹配！\")\n",
    "    else:\n",
    "        print(f\"第{i+1}层 ({num_layer_options[i]}层模型): 无可见度数据\")\n",
    "\n",
    "# 可视化训练损失\n",
    "if results['losses'] and any(results['losses']):\n",
    "    print(\"可视化训练损失...\")\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for i, num_layers in enumerate(num_layer_options):\n",
    "        if results['losses'][i]:  # 确保有损失数据\n",
    "            plt.plot(results['losses'][i], label=f'{num_layers} Layer(s)')\n",
    "    plt.xlabel('Epoches')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Losses through layers')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(f\"{config.save_dir}/training_losses.png\", dpi=300)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99763ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 阶段4: 光场传播仿真 =====\n",
    "import glob\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"阶段4: 光场传播仿真\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# 创建掩码加载器\n",
    "mask_loader = SimpleMaskLoader(config)\n",
    "\n",
    "# 创建仿真器\n",
    "simulator = Simulator(config, evaluation_regions=evaluation_regions)\n",
    "\n",
    "run_simulation = True\n",
    "\n",
    "if run_simulation:\n",
    "    print(\"开始光场传播仿真...\")\n",
    "    \n",
    "    # **关键修复：只生成一次输入场，供所有模型使用**\n",
    "    print(\"生成多模式输入场...\")\n",
    "    input_fields = data_generator.generate_input_data()\n",
    "    print(f\"✓ 生成输入场完成，形状: {input_fields.shape}\")\n",
    "    print(f\"  模式数: {input_fields.shape[0]}\")\n",
    "    print(f\"  波长数: {input_fields.shape[1]}\")\n",
    "    print(f\"  空间尺寸: {input_fields.shape[2]}×{input_fields.shape[3]}\")\n",
    "    \n",
    "    # 选择要仿真的模型\n",
    "    simulation_results = {}\n",
    "    \n",
    "    for i, num_layers in enumerate(num_layer_options):\n",
    "        if i < len(results['models']) and results['models'][i] is not None:\n",
    "            print(f\"\\n{'='*60}\")\n",
    "            print(f\"仿真 {num_layers} 层模型 ({i+1}/{len(num_layer_options)})\")\n",
    "            print(f\"{'='*60}\")\n",
    "            \n",
    "            try:\n",
    "                # 获取训练好的相位掩码\n",
    "                if i < len(results['phase_masks']) and results['phase_masks'][i]:\n",
    "                    phase_masks = results['phase_masks'][i]\n",
    "                    print(f\"✓ 使用训练好的 {num_layers} 层相位掩码\")\n",
    "                    print(f\"  掩码层数: {len(phase_masks)}\")\n",
    "                    print(f\"  每层波长数: {len(phase_masks[0]) if phase_masks else 0}\")\n",
    "                else:\n",
    "                    # 使用备用掩码\n",
    "                    phase_masks = mask_loader.get_masks_for_simulation(None, num_layers)\n",
    "                    print(f\"⚠ 使用备用 {num_layers} 层相位掩码\")\n",
    "                \n",
    "                # 执行仿真\n",
    "                print(\"执行光场传播...\")\n",
    "                propagation_results = simulator.simulate_propagation(\n",
    "                    phase_masks=phase_masks,\n",
    "                    input_field=input_fields,  # 使用同一个输入场\n",
    "                    process_all_modes=True\n",
    "                )\n",
    "                \n",
    "                # 验证仿真结果\n",
    "                print(f\"仿真结果验证:\")\n",
    "                print(f\"  结果数量: {len(propagation_results) if propagation_results else 0}\")\n",
    "                \n",
    "                if propagation_results:\n",
    "                    # 按模式统计结果\n",
    "                    mode_counts = {}\n",
    "                    for result in propagation_results:\n",
    "                        if isinstance(result, dict):\n",
    "                            mode_idx = result.get('mode_idx', 0)\n",
    "                            mode_counts[mode_idx] = mode_counts.get(mode_idx, 0) + 1\n",
    "                    \n",
    "                    print(f\"  模式分布: {mode_counts}\")\n",
    "                    \n",
    "                    # 显示前几个结果的详细信息 - 修复：使用一致的显示标签\n",
    "                    for idx, result in enumerate(propagation_results[:6]):  # 显示前6个结果\n",
    "                        if isinstance(result, dict):\n",
    "                            mode_idx = result.get('mode_idx', 0)  # 内部索引 0-2\n",
    "                            wl_idx = result.get('wavelength_idx', 0)\n",
    "                            focus_ratio = result.get('focus_ratio', 0)\n",
    "                            peak_intensity = result.get('peak_intensity', 0)\n",
    "                            \n",
    "                            wl_nm = config.wavelengths[wl_idx] * 1e9 if wl_idx < len(config.wavelengths) else 0\n",
    "                            # 修复：显示标签使用 mode_idx+1，保持与图表一致\n",
    "                            display_mode = mode_idx + 1  # 转换为显示标签 1-3\n",
    "                            print(f\"    结果{idx+1}: 模式{display_mode}, {wl_nm:.0f}nm, 聚焦比例={focus_ratio:.4f}, 峰值={peak_intensity:.6f}\")\n",
    "                \n",
    "                # 保存仿真结果\n",
    "                simulation_results[num_layers] = propagation_results\n",
    "                \n",
    "                print(f\"✅ {num_layers} 层模型仿真完成\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"❌ {num_layers} 层模型仿真失败: {e}\")\n",
    "                import traceback\n",
    "                traceback.print_exc()\n",
    "                continue\n",
    "    \n",
    "    # 验证所有仿真结果\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(\"仿真结果总览\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    total_results = 0\n",
    "    for num_layers, results_list in simulation_results.items():\n",
    "        count = len(results_list) if results_list else 0\n",
    "        total_results += count\n",
    "        print(f\"{num_layers}层模型: {count}个结果\")\n",
    "    \n",
    "    print(f\"总计: {total_results}个仿真结果\")\n",
    "    print(f\"期望: {len(num_layer_options) * config.num_modes * len(config.wavelengths)}个结果\")\n",
    "    \n",
    "    print(\"✓ 光场传播仿真完成\")\n",
    "\n",
    "# ===== 新增：阶段4.5: 仿真结果可视化分析 =====\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"阶段4.5: 仿真结果可视化分析\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "try:\n",
    "    if run_simulation and simulation_results:\n",
    "        print(\"开始创建仿真结果可视化...\")\n",
    "        \n",
    "        # 1. 创建传播结果总结图（为每个层数模型）\n",
    "        print(\"\\n1. 创建传播结果总结图...\")\n",
    "        simulator.create_propagation_summary(config.save_dir)\n",
    "        \n",
    "        # 2. 创建详细分析报告\n",
    "        print(\"\\n2. 创建详细分析报告...\")\n",
    "        simulator.create_detailed_analysis(config.save_dir)\n",
    "        \n",
    "        # 3. 创建性能对比图\n",
    "        print(\"\\n3. 创建性能对比图...\")\n",
    "        simulator.create_performance_comparison(config.save_dir)\n",
    "        \n",
    "        # **新增：4. 基于仿真结果重新计算并可视化 visibility**\n",
    "        print(\"\\n4. 基于仿真结果计算真实 visibility...\")\n",
    "        visualizer = Visualizer(config)\n",
    "        \n",
    "        # 从仿真结果计算真实 visibility\n",
    "        real_visibility_data = visualizer.calculate_visibility_from_simulation_results(\n",
    "            config.save_dir, config, num_layer_options\n",
    "        )\n",
    "        \n",
    "        if real_visibility_data:\n",
    "            # 创建基于真实仿真结果的 visibility 分析图\n",
    "            print(\"创建真实 visibility 分析图...\")\n",
    "            visualizer.create_detailed_visibility_analysis(\n",
    "                real_visibility_data, config, num_layer_options, \n",
    "                save_path=os.path.join(config.save_dir, 'real_visibility_analysis.png'),\n",
    "                title_suffix=\"(基于仿真结果)\"\n",
    "            )\n",
    "            \n",
    "            # 对比原始 visibility 和真实 visibility（如果有原始数据）\n",
    "            if valid_results and 'visibility' in results and results['visibility']:\n",
    "                print(\"创建 visibility 对比分析...\")\n",
    "                \n",
    "                # 组织原始 visibility 数据\n",
    "                original_visibility = visualizer.organize_visibility_by_mode(\n",
    "                    results, config, num_layer_options\n",
    "                )\n",
    "                \n",
    "                # 创建对比图\n",
    "                visualizer.create_visibility_comparison(\n",
    "                    original_visibility=original_visibility,\n",
    "                    real_visibility=real_visibility_data,\n",
    "                    config=config,\n",
    "                    num_layer_options=num_layer_options,\n",
    "                    save_path=os.path.join(config.save_dir, 'visibility_comparison.png')\n",
    "                )\n",
    "                \n",
    "                print(\"✅ Visibility 对比分析完成\")\n",
    "            else:\n",
    "                print(\"⚠ 没有原始 visibility 数据，跳过对比分析\")\n",
    "            \n",
    "            # 创建综合分析报告\n",
    "            print(\"创建综合 visibility 分析报告...\")\n",
    "            visualizer.create_comprehensive_visibility_report(\n",
    "                real_visibility_data, config, num_layer_options, config.save_dir\n",
    "            )\n",
    "            \n",
    "        else:\n",
    "            print(\"❌ 无法从仿真结果计算 visibility\")\n",
    "        \n",
    "        # 5. 为每个模式创建可视化（可选）- 修复：使用正确的显示标签\n",
    "        print(\"\\n5. 创建各模式传播结果可视化...\")\n",
    "        for mode_idx in range(config.num_modes):\n",
    "            display_mode = mode_idx + 1  # 转换为显示标签\n",
    "            mode_suffix = f\"_mode{display_mode}\"  # 使用显示标签命名\n",
    "            simulator.visualize_propagation_results(config.save_dir, mode_suffix)\n",
    "        \n",
    "        print(\"\\n✅ 仿真结果可视化完成\")\n",
    "        \n",
    "        # 生成最终总结报告\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(\"🎯 仿真分析总结\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        print(f\"✅ 仿真完成的模型: {len(simulation_results)}/{len(num_layer_options)}\")\n",
    "        \n",
    "        # 统计生成的文件\n",
    "        npy_files = glob.glob(os.path.join(config.save_dir, 'MC_single_*.npy'))\n",
    "        png_files = glob.glob(os.path.join(config.save_dir, '*.png'))\n",
    "        json_files = glob.glob(os.path.join(config.save_dir, '*.json'))\n",
    "        csv_files = glob.glob(os.path.join(config.save_dir, '*.csv'))\n",
    "        \n",
    "        print(f\"✅ 生成的仿真数据文件: {len(npy_files)}\")\n",
    "        print(f\"✅ 生成的可视化图表: {len(png_files)}\")\n",
    "        print(f\"✅ 生成的数据分析文件: {len(json_files)} JSON, {len(csv_files)} CSV\")\n",
    "        \n",
    "        print(f\"\\n📊 生成的主要图表文件:\")\n",
    "        key_images = [\n",
    "            'real_visibility_analysis.png',\n",
    "            'visibility_comparison.png', \n",
    "            'detailed_visibility_analysis.png',\n",
    "            'mode_wavelength_matrix.png',\n",
    "            'visibility_statistics_visualization.png',\n",
    "            'performance_comparison.png'\n",
    "        ]\n",
    "        \n",
    "        for img_file in key_images:\n",
    "            img_path = os.path.join(config.save_dir, img_file)\n",
    "            if os.path.exists(img_path):\n",
    "                print(f\"  ✅ {img_file}\")\n",
    "            else:\n",
    "                print(f\"  ❌ {img_file} (未生成)\")\n",
    "        \n",
    "        print(f\"\\n📁 所有结果保存在: {config.save_dir}\")\n",
    "        \n",
    "        # 检查是否有分析报告\n",
    "        report_files = [\n",
    "            'detailed_analysis_report.txt',\n",
    "            'detailed_analysis_data.json',\n",
    "            'visibility_statistics.json',\n",
    "            'visibility_data.csv',\n",
    "            'analysis_summary.json'\n",
    "        ]\n",
    "        \n",
    "        print(f\"\\n📋 分析报告:\")\n",
    "        for report_file in report_files:\n",
    "            report_path = os.path.join(config.save_dir, report_file)\n",
    "            if os.path.exists(report_path):\n",
    "                print(f\"  ✅ {report_file}\")\n",
    "            else:\n",
    "                print(f\"  ❌ {report_file} (未生成)\")\n",
    "        \n",
    "        # 运行完整分析流程（这是一个综合方法）\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(\"运行完整分析流程...\")\n",
    "        print(f\"{'='*50}\")\n",
    "        simulator.run_complete_analysis(config.save_dir)\n",
    "        \n",
    "        # **新增：创建最终的综合报告**\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(\"创建最终综合分析报告...\")\n",
    "        print(f\"{'='*50}\")\n",
    "        \n",
    "        try:\n",
    "            # 如果有真实 visibility 数据，创建完整的分析报告\n",
    "            if real_visibility_data:\n",
    "                visualizer.create_complete_analysis_report(\n",
    "                    results={'visibility': real_visibility_data}, \n",
    "                    config=config, \n",
    "                    num_layer_options=num_layer_options, \n",
    "                    save_dir=config.save_dir\n",
    "                )\n",
    "                print(\"✅ 综合分析报告创建完成\")\n",
    "            \n",
    "            # 创建性能总结 - 修复：使用一致的显示标签\n",
    "            print(\"\\n📈 性能分析总结:\")\n",
    "            if real_visibility_data:\n",
    "                all_values = []\n",
    "                best_configs = []\n",
    "                \n",
    "                for mode_idx, mode_data in enumerate(real_visibility_data):\n",
    "                    mode_array = np.array(mode_data)\n",
    "                    all_values.extend(mode_array.flatten())\n",
    "                    \n",
    "                    # 找到每个模式的最佳配置\n",
    "                    if mode_array.size > 0:\n",
    "                        best_pos = np.unravel_index(np.argmax(mode_array), mode_array.shape)\n",
    "                        best_layer = num_layer_options[best_pos[0]]\n",
    "                        best_wl = config.wavelengths[best_pos[1]] * 1e9\n",
    "                        best_vis = mode_array[best_pos]\n",
    "                        \n",
    "                        display_mode = mode_idx + 1  # 转换为显示标签\n",
    "                        best_configs.append({\n",
    "                            'mode': display_mode,  # 使用显示标签\n",
    "                            'layers': best_layer,\n",
    "                            'wavelength': int(best_wl),\n",
    "                            'visibility': best_vis\n",
    "                        })\n",
    "                        \n",
    "                        # 修复：显示时使用一致的标签\n",
    "                        print(f\"  模式 {display_mode}: {best_layer}层@{int(best_wl)}nm, visibility={best_vis:.4f}\")\n",
    "                \n",
    "                if all_values:\n",
    "                    overall_max = np.max(all_values)\n",
    "                    overall_avg = np.mean(all_values)\n",
    "                    \n",
    "                    print(f\"\\n🏆 整体性能:\")\n",
    "                    print(f\"  最大 visibility: {overall_max:.4f}\")\n",
    "                    print(f\"  平均 visibility: {overall_avg:.4f}\")\n",
    "                    print(f\"  有效配置数: {np.sum(np.array(all_values) > 0.01)}/{len(all_values)}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"❌ 创建综合分析报告失败: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"❌ 仿真结果可视化失败: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n",
    "print(\"\\n🎉 仿真和可视化分析完成！\")\n",
    "\n",
    "# ===== 阶段5: 模型与仿真对比分析 =====\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"阶段5: 模型与仿真对比分析\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "if run_simulation and simulation_results and valid_results:\n",
    "    print(\"开始模型预测与仿真结果对比...\")\n",
    "    \n",
    "    try:\n",
    "        # 创建对比分析\n",
    "        comparison_results = {}\n",
    "        \n",
    "        for i, num_layers in enumerate(num_layer_options):\n",
    "            if (i in valid_results and \n",
    "                num_layers in simulation_results and \n",
    "                i < len(results['weights_pred']) and \n",
    "                results['weights_pred'][i] is not None):\n",
    "                \n",
    "                print(f\"\\n{'='*40}\")\n",
    "                print(f\"分析 {num_layers} 层模型\")\n",
    "                print(f\"{'='*40}\")\n",
    "                \n",
    "                # 获取模型预测结果 - 修复numpy数组判断问题\n",
    "                model_predictions = results['weights_pred'][i]\n",
    "                \n",
    "                # 安全地检查模型预测数据\n",
    "                if model_predictions is not None:\n",
    "                    if isinstance(model_predictions, np.ndarray):\n",
    "                        # 展平多维数组\n",
    "                        model_predictions_flat = model_predictions.flatten()\n",
    "                        model_pred_len = len(model_predictions_flat)\n",
    "                        has_model_pred = model_predictions_flat.size > 0\n",
    "                        print(f\"模型预测原始形状: {model_predictions.shape}\")\n",
    "                        print(f\"模型预测展平后长度: {model_pred_len}\")\n",
    "                    else:\n",
    "                        model_predictions_flat = model_predictions\n",
    "                        model_pred_len = len(model_predictions) if model_predictions else 0\n",
    "                        has_model_pred = bool(model_predictions)\n",
    "                        print(f\"模型预测数据长度: {model_pred_len}\")\n",
    "                else:\n",
    "                    model_predictions_flat = []\n",
    "                    model_pred_len = 0\n",
    "                    has_model_pred = False\n",
    "                    print(f\"模型预测数据长度: 0\")\n",
    "                \n",
    "                # 获取仿真结果\n",
    "                sim_results = simulation_results[num_layers]\n",
    "                has_sim_results = bool(sim_results)\n",
    "                print(f\"仿真结果数量: {len(sim_results) if has_sim_results else 0}\")\n",
    "                \n",
    "                if has_model_pred and has_sim_results:\n",
    "                    # 重新组织仿真结果以匹配模型预测格式\n",
    "                    # 期望格式：[mode0_wl0, mode0_wl1, mode0_wl2, mode1_wl0, mode1_wl1, mode1_wl2, ...]\n",
    "                    \n",
    "                    # 按模式和波长组织仿真结果\n",
    "                    organized_sim_results = {}\n",
    "                    for result in sim_results:\n",
    "                        if isinstance(result, dict):\n",
    "                            mode_idx = result.get('mode_idx', 0)  # 内部索引 0-2\n",
    "                            wl_idx = result.get('wavelength_idx', 0)\n",
    "                            key = (mode_idx, wl_idx)\n",
    "                            organized_sim_results[key] = result\n",
    "                    \n",
    "                    print(f\"组织后的仿真结果键: {sorted(organized_sim_results.keys())}\")\n",
    "                    \n",
    "                    # 提取对应的检测器响应\n",
    "                    sim_detector_responses = []\n",
    "                    expected_keys = []\n",
    "                    \n",
    "                    for mode_idx in range(config.num_modes):  # 内部索引 0-2\n",
    "                        for wl_idx in range(len(config.wavelengths)):\n",
    "                            key = (mode_idx, wl_idx)\n",
    "                            expected_keys.append(key)\n",
    "                            \n",
    "                            if key in organized_sim_results:\n",
    "                                result = organized_sim_results[key]\n",
    "                                # 使用聚焦比例作为主要指标\n",
    "                                response = result.get('focus_ratio', 0.0)\n",
    "                                sim_detector_responses.append(response)\n",
    "                            else:\n",
    "                                # 修复：显示时使用显示标签，但内部仍使用内部索引\n",
    "                                display_mode = mode_idx + 1\n",
    "                                print(f\"  ⚠ 缺少模式{display_mode}波长{wl_idx}的仿真结果\")\n",
    "                                sim_detector_responses.append(0.0)\n",
    "                    \n",
    "                    print(f\"期望的键: {expected_keys}\")\n",
    "                    print(f\"仿真响应长度: {len(sim_detector_responses)}\")\n",
    "                    print(f\"模型预测长度: {model_pred_len}\")\n",
    "                    \n",
    "                    # 确保长度匹配 - 处理长度不同的情况\n",
    "                    min_len = min(model_pred_len, len(sim_detector_responses))\n",
    "                    \n",
    "                    if min_len > 1:\n",
    "                        # 安全地转换为numpy数组并确保是1维的\n",
    "                        model_array = np.array(model_predictions_flat[:min_len]).flatten()\n",
    "                        sim_array = np.array(sim_detector_responses[:min_len]).flatten()\n",
    "                        \n",
    "                        print(f\"  处理后的数组形状:\")\n",
    "                        print(f\"    模型预测: {model_array.shape}\")\n",
    "                        print(f\"    仿真结果: {sim_array.shape}\")\n",
    "                        \n",
    "                        # 检查数据有效性\n",
    "                        if len(model_array) == len(sim_array) and len(model_array) > 1:\n",
    "                            # 归一化数据以提高相关性计算的稳定性\n",
    "                            model_std = np.std(model_array)\n",
    "                            sim_std = np.std(sim_array)\n",
    "                            \n",
    "                            print(f\"  数据统计:\")\n",
    "                            print(f\"    模型预测 - 均值: {np.mean(model_array):.6f}, 标准差: {model_std:.6f}\")\n",
    "                            print(f\"    仿真结果 - 均值: {np.mean(sim_array):.6f}, 标准差: {sim_std:.6f}\")\n",
    "                            \n",
    "                            if model_std > 1e-10 and sim_std > 1e-10:\n",
    "                                model_norm = (model_array - np.mean(model_array)) / model_std\n",
    "                                sim_norm = (sim_array - np.mean(sim_array)) / sim_std\n",
    "                                \n",
    "                                # 计算相关系数 - 确保输入是1维数组\n",
    "                                try:\n",
    "                                    correlation_matrix = np.corrcoef(model_norm, sim_norm)\n",
    "                                    correlation = correlation_matrix[0, 1]\n",
    "                                    \n",
    "                                    # 检查相关系数是否有效\n",
    "                                    if np.isnan(correlation):\n",
    "                                        correlation = 0.0\n",
    "                                        print(f\"  ⚠ 相关系数为NaN，设置为0\")\n",
    "                                    \n",
    "                                except Exception as corr_e:\n",
    "                                    print(f\"  ⚠ 计算相关系数失败: {corr_e}\")\n",
    "                                    correlation = 0.0\n",
    "                                \n",
    "                                # 计算RMSE（使用原始数据）\n",
    "                                rmse = np.sqrt(np.mean((model_array - sim_array)**2))\n",
    "                                \n",
    "                                # 计算平均绝对误差\n",
    "                                mae = np.mean(np.abs(model_array - sim_array))\n",
    "                                \n",
    "                                comparison_results[num_layers] = {\n",
    "                                    'correlation': float(correlation),\n",
    "                                    'rmse': float(rmse),\n",
    "                                    'mae': float(mae),\n",
    "                                    'model_predictions': model_predictions_flat.tolist() if isinstance(model_predictions_flat, np.ndarray) else model_predictions_flat,\n",
    "                                    'simulation_results': sim_detector_responses,\n",
    "                                    'data_length': min_len\n",
    "                                }\n",
    "                                \n",
    "                                print(f\"  ✅ 分析完成:\")\n",
    "                                print(f\"    数据长度: {min_len}\")\n",
    "                                print(f\"    相关系数: {correlation:.4f}\")\n",
    "                                print(f\"    RMSE: {rmse:.4f}\")\n",
    "                                print(f\"    MAE: {mae:.4f}\")\n",
    "                                print(f\"    模型预测范围: [{np.min(model_array):.4f}, {np.max(model_array):.4f}]\")\n",
    "                                print(f\"    仿真结果范围: [{np.min(sim_array):.4f}, {np.max(sim_array):.4f}]\")\n",
    "                            else:\n",
    "                                print(f\"  ⚠ 数据标准差过小，无法计算相关性\")\n",
    "                                print(f\"    模型标准差: {model_std}\")\n",
    "                                print(f\"    仿真标准差: {sim_std}\")\n",
    "                        else:\n",
    "                            print(f\"  ⚠ 数组长度不匹配或长度不足\")\n",
    "                            print(f\"    模型数组长度: {len(model_array)}\")\n",
    "                            print(f\"    仿真数组长度: {len(sim_array)}\")\n",
    "                    else:\n",
    "                        print(f\"  ⚠ 数据长度不足 (min_len={min_len})，无法计算相关性\")\n",
    "                else:\n",
    "                    print(f\"  ⚠ 缺少有效的预测或仿真数据\")\n",
    "                    print(f\"    模型预测有效: {has_model_pred}\")\n",
    "                    print(f\"    仿真结果有效: {has_sim_results}\")\n",
    "        \n",
    "        # 可视化对比结果\n",
    "        if comparison_results:\n",
    "            print(f\"\\n可视化模型-仿真对比结果...\")\n",
    "            \n",
    "            fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "            \n",
    "            layers_list = sorted(comparison_results.keys())\n",
    "            correlations = [comparison_results[l]['correlation'] for l in layers_list]\n",
    "            rmses = [comparison_results[l]['rmse'] for l in layers_list]\n",
    "            maes = [comparison_results[l]['mae'] for l in layers_list]\n",
    "            \n",
    "            # 相关系数图\n",
    "            ax1 = axes[0, 0]\n",
    "            bars1 = ax1.bar(range(len(layers_list)), correlations, alpha=0.7, color='skyblue')\n",
    "            ax1.set_xlabel('层数')\n",
    "            ax1.set_ylabel('相关系数')\n",
    "            ax1.set_title('模型预测与仿真结果相关性')\n",
    "            ax1.set_xticks(range(len(layers_list)))\n",
    "            ax1.set_xticklabels([f'{l}层' for l in layers_list])\n",
    "            ax1.grid(True, alpha=0.3)\n",
    "            ax1.set_ylim(-1, 1)\n",
    "            ax1.axhline(y=0, color='red', linestyle='--', alpha=0.5)\n",
    "            \n",
    "            # 添加数值标签\n",
    "            for i, (bar, v) in enumerate(zip(bars1, correlations)):\n",
    "                height = bar.get_height()\n",
    "                ax1.text(bar.get_x() + bar.get_width()/2., height + 0.02 if height >= 0 else height - 0.05,\n",
    "                        f'{v:.3f}', ha='center', va='bottom' if height >= 0 else 'top')\n",
    "            \n",
    "            # RMSE图\n",
    "            ax2 = axes[0, 1]\n",
    "            bars2 = ax2.bar(range(len(layers_list)), rmses, alpha=0.7, color='lightcoral')\n",
    "            ax2.set_xlabel('层数')\n",
    "            ax2.set_ylabel('RMSE')\n",
    "            ax2.set_title('模型预测与仿真结果RMSE')\n",
    "            ax2.set_xticks(range(len(layers_list)))\n",
    "            ax2.set_xticklabels([f'{l}层' for l in layers_list])\n",
    "            ax2.grid(True, alpha=0.3)\n",
    "            \n",
    "            # 添加数值标签\n",
    "            for i, (bar, v) in enumerate(zip(bars2, rmses)):\n",
    "                height = bar.get_height()\n",
    "                if rmses:  # 防止除零错误\n",
    "                    ax2.text(bar.get_x() + bar.get_width()/2., height + max(rmses)*0.01,\n",
    "                            f'{v:.3f}', ha='center', va='bottom')\n",
    "            \n",
    "            # MAE图\n",
    "            ax3 = axes[1, 0]\n",
    "            bars3 = ax3.bar(range(len(layers_list)), maes, alpha=0.7, color='lightgreen')\n",
    "            ax3.set_xlabel('层数')\n",
    "            ax3.set_ylabel('MAE')\n",
    "            ax3.set_title('模型预测与仿真结果MAE')\n",
    "            ax3.set_xticks(range(len(layers_list)))\n",
    "            ax3.set_xticklabels([f'{l}层' for l in layers_list])\n",
    "            ax3.grid(True, alpha=0.3)\n",
    "            \n",
    "            # 添加数值标签\n",
    "            for i, (bar, v) in enumerate(zip(bars3, maes)):\n",
    "                height = bar.get_height()\n",
    "                if maes:  # 防止除零错误\n",
    "                    ax3.text(bar.get_x() + bar.get_width()/2., height + max(maes)*0.01,\n",
    "                            f'{v:.3f}', ha='center', va='bottom')\n",
    "            \n",
    "            # 散点图：选择最佳相关性的模型\n",
    "            ax4 = axes[1, 1]\n",
    "            if correlations:\n",
    "                best_idx = np.argmax(np.abs(correlations))  # 选择绝对值最大的相关系数\n",
    "                best_layer = layers_list[best_idx]\n",
    "                \n",
    "                model_pred = comparison_results[best_layer]['model_predictions']\n",
    "                sim_results_data = comparison_results[best_layer]['simulation_results']\n",
    "                \n",
    "                min_len = min(len(model_pred), len(sim_results_data))\n",
    "                model_array = np.array(model_pred[:min_len])\n",
    "                sim_array = np.array(sim_results_data[:min_len])\n",
    "                \n",
    "                ax4.scatter(model_array, sim_array, alpha=0.7, s=50)\n",
    "                # 计算理想匹配线的范围\n",
    "                all_values = np.concatenate([model_array, sim_array])\n",
    "                min_val, max_val = np.min(all_values), np.max(all_values)\n",
    "                ax4.plot([min_val, max_val], [min_val, max_val], \n",
    "                        'r--', alpha=0.8, label='理想匹配线')\n",
    "                \n",
    "                ax4.set_xlabel('模型预测值')\n",
    "                ax4.set_ylabel('仿真结果值')\n",
    "                ax4.set_title(f'最佳匹配模型散点图 ({best_layer}层)\\nr={correlations[best_idx]:.3f}')\n",
    "                ax4.legend()\n",
    "                ax4.grid(True, alpha=0.3)\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f\"{config.save_dir}/model_simulation_comparison.png\", dpi=300)\n",
    "            plt.show()\n",
    "            \n",
    "            # 打印详细的对比分析结果\n",
    "            print(f\"\\n🏆 详细对比分析总结:\")\n",
    "            print(f\"{'='*50}\")\n",
    "            \n",
    "            if correlations:\n",
    "                best_corr_idx = np.argmax(np.abs(correlations))  # 绝对值最大\n",
    "                best_rmse_idx = np.argmin(rmses)\n",
    "                best_mae_idx = np.argmin(maes)\n",
    "                \n",
    "                print(f\"最佳相关性: {layers_list[best_corr_idx]}层\")\n",
    "                print(f\"  相关系数: {correlations[best_corr_idx]:.4f}\")\n",
    "                print(f\"  数据点数: {comparison_results[layers_list[best_corr_idx]]['data_length']}\")\n",
    "                \n",
    "                print(f\"\\n最低RMSE: {layers_list[best_rmse_idx]}层\")\n",
    "                print(f\"  RMSE: {rmses[best_rmse_idx]:.4f}\")\n",
    "                \n",
    "                print(f\"\\n最低MAE: {layers_list[best_mae_idx]}层\")\n",
    "                print(f\"  MAE: {maes[best_mae_idx]:.4f}\")\n",
    "                \n",
    "                # 保存详细对比数据\n",
    "                detailed_comparison = {\n",
    "                    'summary': {\n",
    "                        'best_correlation': {\n",
    "                            'layers': int(layers_list[best_corr_idx]), \n",
    "                            'value': float(correlations[best_corr_idx]),\n",
    "                            'data_points': int(comparison_results[layers_list[best_corr_idx]]['data_length'])\n",
    "                        },\n",
    "                        'best_rmse': {\n",
    "                            'layers': int(layers_list[best_rmse_idx]), \n",
    "                            'value': float(rmses[best_rmse_idx])\n",
    "                        },\n",
    "                        'best_mae': {\n",
    "                            'layers': int(layers_list[best_mae_idx]), \n",
    "                            'value': float(maes[best_mae_idx])\n",
    "                        }\n",
    "                    },\n",
    "                    'detailed_results': {}\n",
    "                }\n",
    "                \n",
    "                for layer in layers_list:\n",
    "                    detailed_comparison['detailed_results'][f'{layer}_layers'] = {\n",
    "                        'correlation': float(comparison_results[layer]['correlation']),\n",
    "                        'rmse': float(comparison_results[layer]['rmse']),\n",
    "                        'mae': float(comparison_results[layer]['mae']),\n",
    "                        'data_length': int(comparison_results[layer]['data_length'])\n",
    "                    }\n",
    "                                \n",
    "                import json\n",
    "                with open(f\"{config.save_dir}/detailed_model_simulation_comparison.json\", 'w') as f:\n",
    "                    json.dump(detailed_comparison, f, indent=2)\n",
    "                \n",
    "                print(f\"\\n✓ 详细对比数据已保存到: {config.save_dir}/detailed_model_simulation_comparison.json\")\n",
    "            \n",
    "        else:\n",
    "            print(\"❌ 没有有效的对比结果\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ 模型与仿真对比分析失败: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "else:\n",
    "    print(\"跳过模型与仿真对比分析（缺少必要数据）\")\n",
    "\n",
    "print(\"✓ 模型与仿真对比分析完成\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ODNN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9bbba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "å¤šæ¨¡å¼å¤šæ³¢é•¿å…‰åœºè°ƒåˆ¶ç³»ç»Ÿ - ä¸»ç¨‹åºï¼ˆä¿®æ”¹ç‰ˆï¼‰\n",
    "é›†æˆè®­ç»ƒ-ä»¿çœŸå·¥ä½œæµç¨‹ - æ— éœ€é¢å¤–æ¨¡å—ç‰ˆæœ¬\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—\n",
    "from label_utils import create_evaluation_regions_mode_wavelength, evaluate_output, evaluate_all_regions, visualize_labels\n",
    "from config import Config\n",
    "from data_generator import MultiModeMultiWavelengthDataGenerator\n",
    "from visualizer import Visualizer\n",
    "from trainer import Trainer\n",
    "from model import MultiModeMultiWavelengthModel\n",
    "from simulator import Simulator\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# è®¾ç½®éšæœºç§å­ï¼Œç¡®ä¿ç»“æœå¯é‡ç°\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"å¤šæ¨¡å¼å¤šæ³¢é•¿å…‰åœºè°ƒåˆ¶ç³»ç»Ÿ - è®­ç»ƒ-ä»¿çœŸé›†æˆç‰ˆ\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ===== æ©ç åŠ è½½å™¨ç±»ï¼ˆå†…è”å®šä¹‰ï¼‰=====\n",
    "class SimpleMaskLoader:\n",
    "    \"\"\"ç®€åŒ–çš„ç›¸ä½æ©ç åŠ è½½å™¨\"\"\"\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "    \n",
    "    def create_fallback_masks(self, num_layers=3):\n",
    "        \"\"\"åˆ›å»ºå¤‡ç”¨èšç„¦æ©ç \"\"\"\n",
    "        print(\"âš  åˆ›å»ºå¤‡ç”¨èšç„¦æ©ç ...\")\n",
    "        \n",
    "        def create_focusing_mask(size, wavelength, focal_length, pixel_size):\n",
    "            center = size // 2\n",
    "            y, x = np.ogrid[:size, :size]\n",
    "            r_squared = ((x - center) * pixel_size) ** 2 + ((y - center) * pixel_size) ** 2\n",
    "            k = 2 * np.pi / wavelength\n",
    "            phase = -k * r_squared / (2 * focal_length)\n",
    "            return np.mod(phase, 2 * np.pi)\n",
    "        \n",
    "        masks = []\n",
    "        focal_lengths = [50e-3, 100e-3, 150e-3]  # ä¸åŒå±‚çš„ç„¦è·\n",
    "        \n",
    "        for layer_idx in range(num_layers):\n",
    "            layer_masks = []\n",
    "            for wl_idx, wavelength in enumerate(self.config.wavelengths):\n",
    "                focal_length = focal_lengths[layer_idx % len(focal_lengths)]\n",
    "                mask = create_focusing_mask(\n",
    "                    self.config.layer_size, wavelength, focal_length, self.config.pixel_size\n",
    "                )\n",
    "                layer_masks.append(mask)\n",
    "            masks.append(layer_masks)\n",
    "        \n",
    "        print(f\"âœ“ åˆ›å»ºäº† {len(masks)} å±‚å¤‡ç”¨æ©ç \")\n",
    "        return masks\n",
    "    \n",
    "    def get_masks_for_simulation(self, trained_masks=None, num_layers=3):\n",
    "        \"\"\"è·å–ç”¨äºä»¿çœŸçš„æ©ç \"\"\"\n",
    "        if trained_masks is not None:\n",
    "            print(\"âœ“ ä½¿ç”¨è®­ç»ƒå¥½çš„ç›¸ä½æ©ç è¿›è¡Œä»¿çœŸ\")\n",
    "            return trained_masks\n",
    "        else:\n",
    "            print(\"âš  ä½¿ç”¨å¤‡ç”¨æ©ç è¿›è¡Œä»¿çœŸ\")\n",
    "            return self.create_fallback_masks(num_layers)\n",
    "\n",
    "# åˆ›å»ºé…ç½®\n",
    "config = Config(\n",
    "    # åŸºæœ¬å‚æ•°\n",
    "    num_modes=3,                                # æ¨¡å¼æ•°é‡\n",
    "    wavelengths=np.array([450e-9, 550e-9, 650e-9]),  # æ³¢é•¿åˆ—è¡¨(m)\n",
    "    \n",
    "    # ç©ºé—´å‚æ•°\n",
    "    field_size=50,                              # åœºå¤§å°(åƒç´ )\n",
    "    layer_size=200,                             # å±‚å¤§å°(åƒç´ )\n",
    "    focus_radius=5,                             # ç„¦ç‚¹åŠå¾„(åƒç´ )\n",
    "    detectsize=15,                              # æ£€æµ‹åŒºåŸŸå¤§å°(åƒç´ )\n",
    "    \n",
    "    # ç‰©ç†å‚æ•°\n",
    "    z_layers=40e-6,                             # å±‚é—´è·ç¦»(m)\n",
    "    z_prop=300e-6,                              # ä¼ æ’­è·ç¦»(m)\n",
    "    z_step=20e-6,                               # ä¼ æ’­æ­¥é•¿(m)\n",
    "    pixel_size=1e-6,                            # åƒç´ å¤§å°(m)\n",
    "    \n",
    "    # æ£€æµ‹åŒºåŸŸåç§» - ä¸ºæ¯ä¸ªæ³¢é•¿å®šä¹‰ä¸åŒçš„åç§»\n",
    "    offsets=[(0,0), (0,0), (0,0)],           # æ¯ä¸ªæ³¢é•¿çš„æ£€æµ‹åŒºåŸŸåç§»\n",
    "    \n",
    "    # è®­ç»ƒå‚æ•°\n",
    "    learning_rate=0.01,                         # å­¦ä¹ ç‡\n",
    "    lr_decay=0.99,                              # å­¦ä¹ ç‡è¡°å‡\n",
    "    epochs=700,                                 # è®­ç»ƒè½®æ•°\n",
    "    batch_size=16,                               # æ‰¹é‡å¤§å°\n",
    "    \n",
    "    # ä¿å­˜å‚æ•°\n",
    "    save_dir=\"./results_multi_mode_multi_wl/\",  # ä¿å­˜ç›®å½•\n",
    "    flag_savemat=True                           # æ˜¯å¦ä¿å­˜.matæ–‡ä»¶\n",
    ")\n",
    "\n",
    "# ç¡®ä¿ä¿å­˜ç›®å½•å­˜åœ¨\n",
    "os.makedirs(config.save_dir, exist_ok=True)\n",
    "os.makedirs(os.path.join(config.save_dir, \"trained_models\"), exist_ok=True)\n",
    "\n",
    "# ===== é˜¶æ®µ1: æ•°æ®å‡†å¤‡ =====\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"é˜¶æ®µ1: æ•°æ®å‡†å¤‡\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# åˆ›å»ºæ•°æ®ç”Ÿæˆå™¨\n",
    "print(\"åˆ›å»ºæ•°æ®ç”Ÿæˆå™¨...\")\n",
    "data_generator = MultiModeMultiWavelengthDataGenerator(config)\n",
    "\n",
    "# ç”Ÿæˆå¤šæ¨¡å¼å¤šæ³¢é•¿æ ‡ç­¾\n",
    "print(\"ç”Ÿæˆæ ‡ç­¾...\")\n",
    "labels = data_generator.generate_labels()\n",
    "\n",
    "# å¯è§†åŒ–æ ‡ç­¾å¸ƒå±€\n",
    "print(\"å¯è§†åŒ–æ ‡ç­¾å¸ƒå±€...\")\n",
    "visualize_labels(labels, config.wavelengths)\n",
    "\n",
    "# åˆ›å»ºè¯„ä¼°åŒºåŸŸ\n",
    "print(\"åˆ›å»ºè¯„ä¼°åŒºåŸŸ...\")\n",
    "# åœ¨æ‚¨çš„ä¸»ç¨‹åºä¸­ï¼Œåˆ›å»ºevaluation_regionsæ—¶ä¹Ÿè¦ä¼ å…¥åç§»\n",
    "evaluation_regions = create_evaluation_regions_mode_wavelength(\n",
    "    config.layer_size, \n",
    "    config.layer_size, \n",
    "    config.focus_radius, \n",
    "    detectsize=config.detectsize,\n",
    "    offsets=config.offsets  # â† æ·»åŠ åç§»å‚æ•°\n",
    ")\n",
    "\n",
    "print(\"âœ“ æ•°æ®å‡†å¤‡å®Œæˆ\")\n",
    "\n",
    "# ===== é˜¶æ®µ2: æ¨¡å‹è®­ç»ƒ =====\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"é˜¶æ®µ2: æ¨¡å‹è®­ç»ƒ\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# æ£€æŸ¥æ˜¯å¦å­˜åœ¨å·²è®­ç»ƒçš„æ¨¡å‹\n",
    "trained_models_dir = os.path.join(config.save_dir, \"trained_models\")\n",
    "existing_models = []\n",
    "if os.path.exists(trained_models_dir):\n",
    "    model_files = [f for f in os.listdir(trained_models_dir) if f.startswith(\"model_\") and f.endswith(\"layers.pth\")]\n",
    "    existing_models = [f for f in model_files]\n",
    "\n",
    "# å®šä¹‰è¦è®­ç»ƒçš„å±‚æ•°é€‰é¡¹\n",
    "num_layer_options = [1, 2, 3, 4, 5]  # å¯ä»¥æ ¹æ®éœ€è¦è°ƒæ•´å±‚æ•°\n",
    "\n",
    "# è¯¢é—®æ˜¯å¦ä½¿ç”¨ç°æœ‰æ¨¡å‹æˆ–é‡æ–°è®­ç»ƒ\n",
    "use_existing = False\n",
    "if existing_models:\n",
    "    print(f\"å‘ç°å·²å­˜åœ¨çš„è®­ç»ƒæ¨¡å‹: {existing_models}\")\n",
    "    try:\n",
    "        response = input(\"æ˜¯å¦ä½¿ç”¨ç°æœ‰æ¨¡å‹ï¼Ÿ(y/nï¼Œé»˜è®¤n): \").lower().strip()\n",
    "        use_existing = response == 'y'\n",
    "    except:\n",
    "        print(\"ä½¿ç”¨é»˜è®¤é€‰é¡¹ï¼šé‡æ–°è®­ç»ƒ\")\n",
    "        use_existing = False\n",
    "\n",
    "if use_existing and existing_models:\n",
    "    print(\"åŠ è½½ç°æœ‰è®­ç»ƒæ¨¡å‹...\")\n",
    "    results = {'models': [], 'losses': [], 'phase_masks': [], 'weights_pred': [], 'visibility': []}\n",
    "    \n",
    "    for num_layers in num_layer_options:\n",
    "        model_path = os.path.join(trained_models_dir, f\"model_{num_layers}layers.pth\")\n",
    "        if os.path.exists(model_path):\n",
    "            print(f\"åŠ è½½ {num_layers} å±‚æ¨¡å‹...\")\n",
    "            \n",
    "            try:\n",
    "                # åŠ è½½æ¨¡å‹æ£€æŸ¥ç‚¹\n",
    "                checkpoint = torch.load(model_path, map_location='cpu')\n",
    "                \n",
    "                # åˆ›å»ºæ¨¡å‹å®ä¾‹\n",
    "                model = MultiModeMultiWavelengthModel(config, num_layers)\n",
    "                model.load_state_dict(checkpoint['model_state_dict'])\n",
    "                \n",
    "                # æå–ç›¸ä½æ©ç \n",
    "                phase_masks = []\n",
    "                if hasattr(model, 'get_phase_masks_for_simulation'):\n",
    "                    phase_masks = model.get_phase_masks_for_simulation()\n",
    "                else:\n",
    "                    # å…¼å®¹æ—§ç‰ˆæœ¬\n",
    "                    for layer in model.layers:\n",
    "                        phase = layer.phase.detach().cpu().numpy()\n",
    "                        phase = phase % (2 * np.pi)\n",
    "                        wavelength_masks = []\n",
    "                        for _ in range(len(config.wavelengths)):\n",
    "                            wavelength_masks.append(phase)\n",
    "                        phase_masks.append(wavelength_masks)\n",
    "                \n",
    "                # è·å–è®­ç»ƒæŸå¤±å’Œå¯è§åº¦\n",
    "                losses = checkpoint.get('train_losses', [])\n",
    "                weights_pred = checkpoint.get('weights_pred', [])\n",
    "                visibility = checkpoint.get('visibility', [])\n",
    "\n",
    "                \n",
    "                results['models'].append(model)\n",
    "                results['losses'].append(losses)\n",
    "                results['phase_masks'].append(phase_masks)\n",
    "                results['weights_pred'].append(weights_pred)\n",
    "                results['visibility'].append(visibility)\n",
    "                \n",
    "                \n",
    "                print(f\"âœ“ æˆåŠŸåŠ è½½ {num_layers} å±‚æ¨¡å‹\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"âœ— åŠ è½½ {num_layers} å±‚æ¨¡å‹å¤±è´¥: {e}\")\n",
    "                # æ·»åŠ ç©ºç»“æœä»¥ä¿æŒç´¢å¼•ä¸€è‡´\n",
    "                results['models'].append(None)\n",
    "                results['losses'].append([])\n",
    "                results['phase_masks'].append([])\n",
    "                results['weights_pred'].append([])\n",
    "                results['visibility'].append([])\n",
    "        else:\n",
    "            print(f\"âœ— æœªæ‰¾åˆ° {num_layers} å±‚æ¨¡å‹æ–‡ä»¶\")\n",
    "            # æ·»åŠ ç©ºç»“æœä»¥ä¿æŒç´¢å¼•ä¸€è‡´\n",
    "            results['models'].append(None)\n",
    "            results['losses'].append([])\n",
    "            results['phase_masks'].append([])\n",
    "            results['weights_pred'].append([])\n",
    "            results['visibility'].append([])\n",
    "else:\n",
    "    print(\"å¼€å§‹è®­ç»ƒæ–°æ¨¡å‹...\")\n",
    "    \n",
    "    # åˆ›å»ºè®­ç»ƒå™¨\n",
    "    trainer = Trainer(config, data_generator, MultiModeMultiWavelengthModel, evaluation_regions=evaluation_regions)\n",
    "    \n",
    "    # è®­ç»ƒå¤šä¸ªå±‚æ•°çš„æ¨¡å‹\n",
    "    results = trainer.train_multiple_models(num_layer_options)\n",
    "\n",
    "print(\"âœ“ æ¨¡å‹å‡†å¤‡å®Œæˆ\")\n",
    "\n",
    "\n",
    "\n",
    "# ===== é˜¶æ®µ3: ç»“æœåˆ†æ =====\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"é˜¶æ®µ3: ç»“æœåˆ†æ\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# æ£€æŸ¥å¯è§åº¦æ•°æ®ç»“æ„\n",
    "print(\"æ£€æŸ¥è®­ç»ƒç»“æœ...\")\n",
    "print(f\"resultsé”®: {list(results.keys())}\")\n",
    "print(f\"å¯è§åº¦æ•°æ®ç»“æ„: {len(results['visibility'])}å±‚\")\n",
    "\n",
    "valid_results = []\n",
    "for i, vis_data in enumerate(results['visibility']):\n",
    "    if vis_data:  # åªå¤„ç†éç©ºçš„å¯è§åº¦æ•°æ®\n",
    "        expected_length = len(config.wavelengths) * config.num_modes\n",
    "        print(f\"ç¬¬{i+1}å±‚ ({num_layer_options[i]}å±‚æ¨¡å‹):\")\n",
    "        print(f\"  æ•°æ®é•¿åº¦: {len(vis_data)}\")\n",
    "        print(f\"  æœŸæœ›é•¿åº¦: {expected_length} ({len(config.wavelengths)}æ³¢é•¿ Ã— {config.num_modes}æ¨¡å¼)\")\n",
    "        \n",
    "        if len(vis_data) == expected_length:\n",
    "            print(f\"  âœ… æ•°æ®é•¿åº¦åŒ¹é…ï¼\")\n",
    "            valid_results.append(i)\n",
    "            # æŒ‰æ³¢é•¿å’Œæ¨¡å¼é‡æ–°ç»„ç»‡æ˜¾ç¤º\n",
    "            vis_array = np.array(vis_data).reshape(len(config.wavelengths), config.num_modes)\n",
    "            for wl_idx, wl in enumerate(config.wavelengths):\n",
    "                wl_nm = wl * 1e9\n",
    "                print(f\"    {wl_nm:.0f}nm: MODE1={vis_array[wl_idx, 0]:.6f}, MODE2={vis_array[wl_idx, 1]:.6f}, MODE3={vis_array[wl_idx, 2]:.6f}\")\n",
    "        else:\n",
    "            print(f\"  âŒ æ•°æ®é•¿åº¦ä¸åŒ¹é…ï¼\")\n",
    "    else:\n",
    "        print(f\"ç¬¬{i+1}å±‚ ({num_layer_options[i]}å±‚æ¨¡å‹): æ— å¯è§åº¦æ•°æ®\")\n",
    "\n",
    "# å¯è§†åŒ–è®­ç»ƒæŸå¤±\n",
    "if results['losses'] and any(results['losses']):\n",
    "    print(\"å¯è§†åŒ–è®­ç»ƒæŸå¤±...\")\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for i, num_layers in enumerate(num_layer_options):\n",
    "        if results['losses'][i]:  # ç¡®ä¿æœ‰æŸå¤±æ•°æ®\n",
    "            plt.plot(results['losses'][i], label=f'{num_layers} Layer(s)')\n",
    "    plt.xlabel('Epoches')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Losses through layers')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(f\"{config.save_dir}/training_losses.png\", dpi=300)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99763ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== é˜¶æ®µ4: å…‰åœºä¼ æ’­ä»¿çœŸ =====\n",
    "import glob\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"é˜¶æ®µ4: å…‰åœºä¼ æ’­ä»¿çœŸ\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# åˆ›å»ºæ©ç åŠ è½½å™¨\n",
    "mask_loader = SimpleMaskLoader(config)\n",
    "\n",
    "# åˆ›å»ºä»¿çœŸå™¨\n",
    "simulator = Simulator(config, evaluation_regions=evaluation_regions)\n",
    "\n",
    "run_simulation = True\n",
    "\n",
    "if run_simulation:\n",
    "    print(\"å¼€å§‹å…‰åœºä¼ æ’­ä»¿çœŸ...\")\n",
    "    \n",
    "    # **å…³é”®ä¿®å¤ï¼šåªç”Ÿæˆä¸€æ¬¡è¾“å…¥åœºï¼Œä¾›æ‰€æœ‰æ¨¡å‹ä½¿ç”¨**\n",
    "    print(\"ç”Ÿæˆå¤šæ¨¡å¼è¾“å…¥åœº...\")\n",
    "    input_fields = data_generator.generate_input_data()\n",
    "    print(f\"âœ“ ç”Ÿæˆè¾“å…¥åœºå®Œæˆï¼Œå½¢çŠ¶: {input_fields.shape}\")\n",
    "    print(f\"  æ¨¡å¼æ•°: {input_fields.shape[0]}\")\n",
    "    print(f\"  æ³¢é•¿æ•°: {input_fields.shape[1]}\")\n",
    "    print(f\"  ç©ºé—´å°ºå¯¸: {input_fields.shape[2]}Ã—{input_fields.shape[3]}\")\n",
    "    \n",
    "    # é€‰æ‹©è¦ä»¿çœŸçš„æ¨¡å‹\n",
    "    simulation_results = {}\n",
    "    \n",
    "    for i, num_layers in enumerate(num_layer_options):\n",
    "        if i < len(results['models']) and results['models'][i] is not None:\n",
    "            print(f\"\\n{'='*60}\")\n",
    "            print(f\"ä»¿çœŸ {num_layers} å±‚æ¨¡å‹ ({i+1}/{len(num_layer_options)})\")\n",
    "            print(f\"{'='*60}\")\n",
    "            \n",
    "            try:\n",
    "                # è·å–è®­ç»ƒå¥½çš„ç›¸ä½æ©ç \n",
    "                if i < len(results['phase_masks']) and results['phase_masks'][i]:\n",
    "                    phase_masks = results['phase_masks'][i]\n",
    "                    print(f\"âœ“ ä½¿ç”¨è®­ç»ƒå¥½çš„ {num_layers} å±‚ç›¸ä½æ©ç \")\n",
    "                    print(f\"  æ©ç å±‚æ•°: {len(phase_masks)}\")\n",
    "                    print(f\"  æ¯å±‚æ³¢é•¿æ•°: {len(phase_masks[0]) if phase_masks else 0}\")\n",
    "                else:\n",
    "                    # ä½¿ç”¨å¤‡ç”¨æ©ç \n",
    "                    phase_masks = mask_loader.get_masks_for_simulation(None, num_layers)\n",
    "                    print(f\"âš  ä½¿ç”¨å¤‡ç”¨ {num_layers} å±‚ç›¸ä½æ©ç \")\n",
    "                \n",
    "                # æ‰§è¡Œä»¿çœŸ\n",
    "                print(\"æ‰§è¡Œå…‰åœºä¼ æ’­...\")\n",
    "                propagation_results = simulator.simulate_propagation(\n",
    "                    phase_masks=phase_masks,\n",
    "                    input_field=input_fields,  # ä½¿ç”¨åŒä¸€ä¸ªè¾“å…¥åœº\n",
    "                    process_all_modes=True\n",
    "                )\n",
    "                \n",
    "                # éªŒè¯ä»¿çœŸç»“æœ\n",
    "                print(f\"ä»¿çœŸç»“æœéªŒè¯:\")\n",
    "                print(f\"  ç»“æœæ•°é‡: {len(propagation_results) if propagation_results else 0}\")\n",
    "                \n",
    "                if propagation_results:\n",
    "                    # æŒ‰æ¨¡å¼ç»Ÿè®¡ç»“æœ\n",
    "                    mode_counts = {}\n",
    "                    for result in propagation_results:\n",
    "                        if isinstance(result, dict):\n",
    "                            mode_idx = result.get('mode_idx', 0)\n",
    "                            mode_counts[mode_idx] = mode_counts.get(mode_idx, 0) + 1\n",
    "                    \n",
    "                    print(f\"  æ¨¡å¼åˆ†å¸ƒ: {mode_counts}\")\n",
    "                    \n",
    "                    # æ˜¾ç¤ºå‰å‡ ä¸ªç»“æœçš„è¯¦ç»†ä¿¡æ¯ - ä¿®å¤ï¼šä½¿ç”¨ä¸€è‡´çš„æ˜¾ç¤ºæ ‡ç­¾\n",
    "                    for idx, result in enumerate(propagation_results[:6]):  # æ˜¾ç¤ºå‰6ä¸ªç»“æœ\n",
    "                        if isinstance(result, dict):\n",
    "                            mode_idx = result.get('mode_idx', 0)  # å†…éƒ¨ç´¢å¼• 0-2\n",
    "                            wl_idx = result.get('wavelength_idx', 0)\n",
    "                            focus_ratio = result.get('focus_ratio', 0)\n",
    "                            peak_intensity = result.get('peak_intensity', 0)\n",
    "                            \n",
    "                            wl_nm = config.wavelengths[wl_idx] * 1e9 if wl_idx < len(config.wavelengths) else 0\n",
    "                            # ä¿®å¤ï¼šæ˜¾ç¤ºæ ‡ç­¾ä½¿ç”¨ mode_idx+1ï¼Œä¿æŒä¸å›¾è¡¨ä¸€è‡´\n",
    "                            display_mode = mode_idx + 1  # è½¬æ¢ä¸ºæ˜¾ç¤ºæ ‡ç­¾ 1-3\n",
    "                            print(f\"    ç»“æœ{idx+1}: æ¨¡å¼{display_mode}, {wl_nm:.0f}nm, èšç„¦æ¯”ä¾‹={focus_ratio:.4f}, å³°å€¼={peak_intensity:.6f}\")\n",
    "                \n",
    "                # ä¿å­˜ä»¿çœŸç»“æœ\n",
    "                simulation_results[num_layers] = propagation_results\n",
    "                \n",
    "                print(f\"âœ… {num_layers} å±‚æ¨¡å‹ä»¿çœŸå®Œæˆ\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"âŒ {num_layers} å±‚æ¨¡å‹ä»¿çœŸå¤±è´¥: {e}\")\n",
    "                import traceback\n",
    "                traceback.print_exc()\n",
    "                continue\n",
    "    \n",
    "    # éªŒè¯æ‰€æœ‰ä»¿çœŸç»“æœ\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(\"ä»¿çœŸç»“æœæ€»è§ˆ\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    total_results = 0\n",
    "    for num_layers, results_list in simulation_results.items():\n",
    "        count = len(results_list) if results_list else 0\n",
    "        total_results += count\n",
    "        print(f\"{num_layers}å±‚æ¨¡å‹: {count}ä¸ªç»“æœ\")\n",
    "    \n",
    "    print(f\"æ€»è®¡: {total_results}ä¸ªä»¿çœŸç»“æœ\")\n",
    "    print(f\"æœŸæœ›: {len(num_layer_options) * config.num_modes * len(config.wavelengths)}ä¸ªç»“æœ\")\n",
    "    \n",
    "    print(\"âœ“ å…‰åœºä¼ æ’­ä»¿çœŸå®Œæˆ\")\n",
    "\n",
    "# ===== æ–°å¢ï¼šé˜¶æ®µ4.5: ä»¿çœŸç»“æœå¯è§†åŒ–åˆ†æ =====\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"é˜¶æ®µ4.5: ä»¿çœŸç»“æœå¯è§†åŒ–åˆ†æ\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "try:\n",
    "    if run_simulation and simulation_results:\n",
    "        print(\"å¼€å§‹åˆ›å»ºä»¿çœŸç»“æœå¯è§†åŒ–...\")\n",
    "        \n",
    "        # 1. åˆ›å»ºä¼ æ’­ç»“æœæ€»ç»“å›¾ï¼ˆä¸ºæ¯ä¸ªå±‚æ•°æ¨¡å‹ï¼‰\n",
    "        print(\"\\n1. åˆ›å»ºä¼ æ’­ç»“æœæ€»ç»“å›¾...\")\n",
    "        simulator.create_propagation_summary(config.save_dir)\n",
    "        \n",
    "        # 2. åˆ›å»ºè¯¦ç»†åˆ†ææŠ¥å‘Š\n",
    "        print(\"\\n2. åˆ›å»ºè¯¦ç»†åˆ†ææŠ¥å‘Š...\")\n",
    "        simulator.create_detailed_analysis(config.save_dir)\n",
    "        \n",
    "        # 3. åˆ›å»ºæ€§èƒ½å¯¹æ¯”å›¾\n",
    "        print(\"\\n3. åˆ›å»ºæ€§èƒ½å¯¹æ¯”å›¾...\")\n",
    "        simulator.create_performance_comparison(config.save_dir)\n",
    "        \n",
    "        # **æ–°å¢ï¼š4. åŸºäºä»¿çœŸç»“æœé‡æ–°è®¡ç®—å¹¶å¯è§†åŒ– visibility**\n",
    "        print(\"\\n4. åŸºäºä»¿çœŸç»“æœè®¡ç®—çœŸå® visibility...\")\n",
    "        visualizer = Visualizer(config)\n",
    "        \n",
    "        # ä»ä»¿çœŸç»“æœè®¡ç®—çœŸå® visibility\n",
    "        real_visibility_data = visualizer.calculate_visibility_from_simulation_results(\n",
    "            config.save_dir, config, num_layer_options\n",
    "        )\n",
    "        \n",
    "        if real_visibility_data:\n",
    "            # åˆ›å»ºåŸºäºçœŸå®ä»¿çœŸç»“æœçš„ visibility åˆ†æå›¾\n",
    "            print(\"åˆ›å»ºçœŸå® visibility åˆ†æå›¾...\")\n",
    "            visualizer.create_detailed_visibility_analysis(\n",
    "                real_visibility_data, config, num_layer_options, \n",
    "                save_path=os.path.join(config.save_dir, 'real_visibility_analysis.png'),\n",
    "                title_suffix=\"(åŸºäºä»¿çœŸç»“æœ)\"\n",
    "            )\n",
    "            \n",
    "            # å¯¹æ¯”åŸå§‹ visibility å’ŒçœŸå® visibilityï¼ˆå¦‚æœæœ‰åŸå§‹æ•°æ®ï¼‰\n",
    "            if valid_results and 'visibility' in results and results['visibility']:\n",
    "                print(\"åˆ›å»º visibility å¯¹æ¯”åˆ†æ...\")\n",
    "                \n",
    "                # ç»„ç»‡åŸå§‹ visibility æ•°æ®\n",
    "                original_visibility = visualizer.organize_visibility_by_mode(\n",
    "                    results, config, num_layer_options\n",
    "                )\n",
    "                \n",
    "                # åˆ›å»ºå¯¹æ¯”å›¾\n",
    "                visualizer.create_visibility_comparison(\n",
    "                    original_visibility=original_visibility,\n",
    "                    real_visibility=real_visibility_data,\n",
    "                    config=config,\n",
    "                    num_layer_options=num_layer_options,\n",
    "                    save_path=os.path.join(config.save_dir, 'visibility_comparison.png')\n",
    "                )\n",
    "                \n",
    "                print(\"âœ… Visibility å¯¹æ¯”åˆ†æå®Œæˆ\")\n",
    "            else:\n",
    "                print(\"âš  æ²¡æœ‰åŸå§‹ visibility æ•°æ®ï¼Œè·³è¿‡å¯¹æ¯”åˆ†æ\")\n",
    "            \n",
    "            # åˆ›å»ºç»¼åˆåˆ†ææŠ¥å‘Š\n",
    "            print(\"åˆ›å»ºç»¼åˆ visibility åˆ†ææŠ¥å‘Š...\")\n",
    "            visualizer.create_comprehensive_visibility_report(\n",
    "                real_visibility_data, config, num_layer_options, config.save_dir\n",
    "            )\n",
    "            \n",
    "        else:\n",
    "            print(\"âŒ æ— æ³•ä»ä»¿çœŸç»“æœè®¡ç®— visibility\")\n",
    "        \n",
    "        # 5. ä¸ºæ¯ä¸ªæ¨¡å¼åˆ›å»ºå¯è§†åŒ–ï¼ˆå¯é€‰ï¼‰- ä¿®å¤ï¼šä½¿ç”¨æ­£ç¡®çš„æ˜¾ç¤ºæ ‡ç­¾\n",
    "        print(\"\\n5. åˆ›å»ºå„æ¨¡å¼ä¼ æ’­ç»“æœå¯è§†åŒ–...\")\n",
    "        for mode_idx in range(config.num_modes):\n",
    "            display_mode = mode_idx + 1  # è½¬æ¢ä¸ºæ˜¾ç¤ºæ ‡ç­¾\n",
    "            mode_suffix = f\"_mode{display_mode}\"  # ä½¿ç”¨æ˜¾ç¤ºæ ‡ç­¾å‘½å\n",
    "            simulator.visualize_propagation_results(config.save_dir, mode_suffix)\n",
    "        \n",
    "        print(\"\\nâœ… ä»¿çœŸç»“æœå¯è§†åŒ–å®Œæˆ\")\n",
    "        \n",
    "        # ç”Ÿæˆæœ€ç»ˆæ€»ç»“æŠ¥å‘Š\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(\"ğŸ¯ ä»¿çœŸåˆ†ææ€»ç»“\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        print(f\"âœ… ä»¿çœŸå®Œæˆçš„æ¨¡å‹: {len(simulation_results)}/{len(num_layer_options)}\")\n",
    "        \n",
    "        # ç»Ÿè®¡ç”Ÿæˆçš„æ–‡ä»¶\n",
    "        npy_files = glob.glob(os.path.join(config.save_dir, 'MC_single_*.npy'))\n",
    "        png_files = glob.glob(os.path.join(config.save_dir, '*.png'))\n",
    "        json_files = glob.glob(os.path.join(config.save_dir, '*.json'))\n",
    "        csv_files = glob.glob(os.path.join(config.save_dir, '*.csv'))\n",
    "        \n",
    "        print(f\"âœ… ç”Ÿæˆçš„ä»¿çœŸæ•°æ®æ–‡ä»¶: {len(npy_files)}\")\n",
    "        print(f\"âœ… ç”Ÿæˆçš„å¯è§†åŒ–å›¾è¡¨: {len(png_files)}\")\n",
    "        print(f\"âœ… ç”Ÿæˆçš„æ•°æ®åˆ†ææ–‡ä»¶: {len(json_files)} JSON, {len(csv_files)} CSV\")\n",
    "        \n",
    "        print(f\"\\nğŸ“Š ç”Ÿæˆçš„ä¸»è¦å›¾è¡¨æ–‡ä»¶:\")\n",
    "        key_images = [\n",
    "            'real_visibility_analysis.png',\n",
    "            'visibility_comparison.png', \n",
    "            'detailed_visibility_analysis.png',\n",
    "            'mode_wavelength_matrix.png',\n",
    "            'visibility_statistics_visualization.png',\n",
    "            'performance_comparison.png'\n",
    "        ]\n",
    "        \n",
    "        for img_file in key_images:\n",
    "            img_path = os.path.join(config.save_dir, img_file)\n",
    "            if os.path.exists(img_path):\n",
    "                print(f\"  âœ… {img_file}\")\n",
    "            else:\n",
    "                print(f\"  âŒ {img_file} (æœªç”Ÿæˆ)\")\n",
    "        \n",
    "        print(f\"\\nğŸ“ æ‰€æœ‰ç»“æœä¿å­˜åœ¨: {config.save_dir}\")\n",
    "        \n",
    "        # æ£€æŸ¥æ˜¯å¦æœ‰åˆ†ææŠ¥å‘Š\n",
    "        report_files = [\n",
    "            'detailed_analysis_report.txt',\n",
    "            'detailed_analysis_data.json',\n",
    "            'visibility_statistics.json',\n",
    "            'visibility_data.csv',\n",
    "            'analysis_summary.json'\n",
    "        ]\n",
    "        \n",
    "        print(f\"\\nğŸ“‹ åˆ†ææŠ¥å‘Š:\")\n",
    "        for report_file in report_files:\n",
    "            report_path = os.path.join(config.save_dir, report_file)\n",
    "            if os.path.exists(report_path):\n",
    "                print(f\"  âœ… {report_file}\")\n",
    "            else:\n",
    "                print(f\"  âŒ {report_file} (æœªç”Ÿæˆ)\")\n",
    "        \n",
    "        # è¿è¡Œå®Œæ•´åˆ†ææµç¨‹ï¼ˆè¿™æ˜¯ä¸€ä¸ªç»¼åˆæ–¹æ³•ï¼‰\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(\"è¿è¡Œå®Œæ•´åˆ†ææµç¨‹...\")\n",
    "        print(f\"{'='*50}\")\n",
    "        simulator.run_complete_analysis(config.save_dir)\n",
    "        \n",
    "        # **æ–°å¢ï¼šåˆ›å»ºæœ€ç»ˆçš„ç»¼åˆæŠ¥å‘Š**\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(\"åˆ›å»ºæœ€ç»ˆç»¼åˆåˆ†ææŠ¥å‘Š...\")\n",
    "        print(f\"{'='*50}\")\n",
    "        \n",
    "        try:\n",
    "            # å¦‚æœæœ‰çœŸå® visibility æ•°æ®ï¼Œåˆ›å»ºå®Œæ•´çš„åˆ†ææŠ¥å‘Š\n",
    "            if real_visibility_data:\n",
    "                visualizer.create_complete_analysis_report(\n",
    "                    results={'visibility': real_visibility_data}, \n",
    "                    config=config, \n",
    "                    num_layer_options=num_layer_options, \n",
    "                    save_dir=config.save_dir\n",
    "                )\n",
    "                print(\"âœ… ç»¼åˆåˆ†ææŠ¥å‘Šåˆ›å»ºå®Œæˆ\")\n",
    "            \n",
    "            # åˆ›å»ºæ€§èƒ½æ€»ç»“ - ä¿®å¤ï¼šä½¿ç”¨ä¸€è‡´çš„æ˜¾ç¤ºæ ‡ç­¾\n",
    "            print(\"\\nğŸ“ˆ æ€§èƒ½åˆ†ææ€»ç»“:\")\n",
    "            if real_visibility_data:\n",
    "                all_values = []\n",
    "                best_configs = []\n",
    "                \n",
    "                for mode_idx, mode_data in enumerate(real_visibility_data):\n",
    "                    mode_array = np.array(mode_data)\n",
    "                    all_values.extend(mode_array.flatten())\n",
    "                    \n",
    "                    # æ‰¾åˆ°æ¯ä¸ªæ¨¡å¼çš„æœ€ä½³é…ç½®\n",
    "                    if mode_array.size > 0:\n",
    "                        best_pos = np.unravel_index(np.argmax(mode_array), mode_array.shape)\n",
    "                        best_layer = num_layer_options[best_pos[0]]\n",
    "                        best_wl = config.wavelengths[best_pos[1]] * 1e9\n",
    "                        best_vis = mode_array[best_pos]\n",
    "                        \n",
    "                        display_mode = mode_idx + 1  # è½¬æ¢ä¸ºæ˜¾ç¤ºæ ‡ç­¾\n",
    "                        best_configs.append({\n",
    "                            'mode': display_mode,  # ä½¿ç”¨æ˜¾ç¤ºæ ‡ç­¾\n",
    "                            'layers': best_layer,\n",
    "                            'wavelength': int(best_wl),\n",
    "                            'visibility': best_vis\n",
    "                        })\n",
    "                        \n",
    "                        # ä¿®å¤ï¼šæ˜¾ç¤ºæ—¶ä½¿ç”¨ä¸€è‡´çš„æ ‡ç­¾\n",
    "                        print(f\"  æ¨¡å¼ {display_mode}: {best_layer}å±‚@{int(best_wl)}nm, visibility={best_vis:.4f}\")\n",
    "                \n",
    "                if all_values:\n",
    "                    overall_max = np.max(all_values)\n",
    "                    overall_avg = np.mean(all_values)\n",
    "                    \n",
    "                    print(f\"\\nğŸ† æ•´ä½“æ€§èƒ½:\")\n",
    "                    print(f\"  æœ€å¤§ visibility: {overall_max:.4f}\")\n",
    "                    print(f\"  å¹³å‡ visibility: {overall_avg:.4f}\")\n",
    "                    print(f\"  æœ‰æ•ˆé…ç½®æ•°: {np.sum(np.array(all_values) > 0.01)}/{len(all_values)}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ åˆ›å»ºç»¼åˆåˆ†ææŠ¥å‘Šå¤±è´¥: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"âŒ ä»¿çœŸç»“æœå¯è§†åŒ–å¤±è´¥: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n",
    "print(\"\\nğŸ‰ ä»¿çœŸå’Œå¯è§†åŒ–åˆ†æå®Œæˆï¼\")\n",
    "\n",
    "# ===== é˜¶æ®µ5: æ¨¡å‹ä¸ä»¿çœŸå¯¹æ¯”åˆ†æ =====\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"é˜¶æ®µ5: æ¨¡å‹ä¸ä»¿çœŸå¯¹æ¯”åˆ†æ\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "if run_simulation and simulation_results and valid_results:\n",
    "    print(\"å¼€å§‹æ¨¡å‹é¢„æµ‹ä¸ä»¿çœŸç»“æœå¯¹æ¯”...\")\n",
    "    \n",
    "    try:\n",
    "        # åˆ›å»ºå¯¹æ¯”åˆ†æ\n",
    "        comparison_results = {}\n",
    "        \n",
    "        for i, num_layers in enumerate(num_layer_options):\n",
    "            if (i in valid_results and \n",
    "                num_layers in simulation_results and \n",
    "                i < len(results['weights_pred']) and \n",
    "                results['weights_pred'][i] is not None):\n",
    "                \n",
    "                print(f\"\\n{'='*40}\")\n",
    "                print(f\"åˆ†æ {num_layers} å±‚æ¨¡å‹\")\n",
    "                print(f\"{'='*40}\")\n",
    "                \n",
    "                # è·å–æ¨¡å‹é¢„æµ‹ç»“æœ - ä¿®å¤numpyæ•°ç»„åˆ¤æ–­é—®é¢˜\n",
    "                model_predictions = results['weights_pred'][i]\n",
    "                \n",
    "                # å®‰å…¨åœ°æ£€æŸ¥æ¨¡å‹é¢„æµ‹æ•°æ®\n",
    "                if model_predictions is not None:\n",
    "                    if isinstance(model_predictions, np.ndarray):\n",
    "                        # å±•å¹³å¤šç»´æ•°ç»„\n",
    "                        model_predictions_flat = model_predictions.flatten()\n",
    "                        model_pred_len = len(model_predictions_flat)\n",
    "                        has_model_pred = model_predictions_flat.size > 0\n",
    "                        print(f\"æ¨¡å‹é¢„æµ‹åŸå§‹å½¢çŠ¶: {model_predictions.shape}\")\n",
    "                        print(f\"æ¨¡å‹é¢„æµ‹å±•å¹³åé•¿åº¦: {model_pred_len}\")\n",
    "                    else:\n",
    "                        model_predictions_flat = model_predictions\n",
    "                        model_pred_len = len(model_predictions) if model_predictions else 0\n",
    "                        has_model_pred = bool(model_predictions)\n",
    "                        print(f\"æ¨¡å‹é¢„æµ‹æ•°æ®é•¿åº¦: {model_pred_len}\")\n",
    "                else:\n",
    "                    model_predictions_flat = []\n",
    "                    model_pred_len = 0\n",
    "                    has_model_pred = False\n",
    "                    print(f\"æ¨¡å‹é¢„æµ‹æ•°æ®é•¿åº¦: 0\")\n",
    "                \n",
    "                # è·å–ä»¿çœŸç»“æœ\n",
    "                sim_results = simulation_results[num_layers]\n",
    "                has_sim_results = bool(sim_results)\n",
    "                print(f\"ä»¿çœŸç»“æœæ•°é‡: {len(sim_results) if has_sim_results else 0}\")\n",
    "                \n",
    "                if has_model_pred and has_sim_results:\n",
    "                    # é‡æ–°ç»„ç»‡ä»¿çœŸç»“æœä»¥åŒ¹é…æ¨¡å‹é¢„æµ‹æ ¼å¼\n",
    "                    # æœŸæœ›æ ¼å¼ï¼š[mode0_wl0, mode0_wl1, mode0_wl2, mode1_wl0, mode1_wl1, mode1_wl2, ...]\n",
    "                    \n",
    "                    # æŒ‰æ¨¡å¼å’Œæ³¢é•¿ç»„ç»‡ä»¿çœŸç»“æœ\n",
    "                    organized_sim_results = {}\n",
    "                    for result in sim_results:\n",
    "                        if isinstance(result, dict):\n",
    "                            mode_idx = result.get('mode_idx', 0)  # å†…éƒ¨ç´¢å¼• 0-2\n",
    "                            wl_idx = result.get('wavelength_idx', 0)\n",
    "                            key = (mode_idx, wl_idx)\n",
    "                            organized_sim_results[key] = result\n",
    "                    \n",
    "                    print(f\"ç»„ç»‡åçš„ä»¿çœŸç»“æœé”®: {sorted(organized_sim_results.keys())}\")\n",
    "                    \n",
    "                    # æå–å¯¹åº”çš„æ£€æµ‹å™¨å“åº”\n",
    "                    sim_detector_responses = []\n",
    "                    expected_keys = []\n",
    "                    \n",
    "                    for mode_idx in range(config.num_modes):  # å†…éƒ¨ç´¢å¼• 0-2\n",
    "                        for wl_idx in range(len(config.wavelengths)):\n",
    "                            key = (mode_idx, wl_idx)\n",
    "                            expected_keys.append(key)\n",
    "                            \n",
    "                            if key in organized_sim_results:\n",
    "                                result = organized_sim_results[key]\n",
    "                                # ä½¿ç”¨èšç„¦æ¯”ä¾‹ä½œä¸ºä¸»è¦æŒ‡æ ‡\n",
    "                                response = result.get('focus_ratio', 0.0)\n",
    "                                sim_detector_responses.append(response)\n",
    "                            else:\n",
    "                                # ä¿®å¤ï¼šæ˜¾ç¤ºæ—¶ä½¿ç”¨æ˜¾ç¤ºæ ‡ç­¾ï¼Œä½†å†…éƒ¨ä»ä½¿ç”¨å†…éƒ¨ç´¢å¼•\n",
    "                                display_mode = mode_idx + 1\n",
    "                                print(f\"  âš  ç¼ºå°‘æ¨¡å¼{display_mode}æ³¢é•¿{wl_idx}çš„ä»¿çœŸç»“æœ\")\n",
    "                                sim_detector_responses.append(0.0)\n",
    "                    \n",
    "                    print(f\"æœŸæœ›çš„é”®: {expected_keys}\")\n",
    "                    print(f\"ä»¿çœŸå“åº”é•¿åº¦: {len(sim_detector_responses)}\")\n",
    "                    print(f\"æ¨¡å‹é¢„æµ‹é•¿åº¦: {model_pred_len}\")\n",
    "                    \n",
    "                    # ç¡®ä¿é•¿åº¦åŒ¹é… - å¤„ç†é•¿åº¦ä¸åŒçš„æƒ…å†µ\n",
    "                    min_len = min(model_pred_len, len(sim_detector_responses))\n",
    "                    \n",
    "                    if min_len > 1:\n",
    "                        # å®‰å…¨åœ°è½¬æ¢ä¸ºnumpyæ•°ç»„å¹¶ç¡®ä¿æ˜¯1ç»´çš„\n",
    "                        model_array = np.array(model_predictions_flat[:min_len]).flatten()\n",
    "                        sim_array = np.array(sim_detector_responses[:min_len]).flatten()\n",
    "                        \n",
    "                        print(f\"  å¤„ç†åçš„æ•°ç»„å½¢çŠ¶:\")\n",
    "                        print(f\"    æ¨¡å‹é¢„æµ‹: {model_array.shape}\")\n",
    "                        print(f\"    ä»¿çœŸç»“æœ: {sim_array.shape}\")\n",
    "                        \n",
    "                        # æ£€æŸ¥æ•°æ®æœ‰æ•ˆæ€§\n",
    "                        if len(model_array) == len(sim_array) and len(model_array) > 1:\n",
    "                            # å½’ä¸€åŒ–æ•°æ®ä»¥æé«˜ç›¸å…³æ€§è®¡ç®—çš„ç¨³å®šæ€§\n",
    "                            model_std = np.std(model_array)\n",
    "                            sim_std = np.std(sim_array)\n",
    "                            \n",
    "                            print(f\"  æ•°æ®ç»Ÿè®¡:\")\n",
    "                            print(f\"    æ¨¡å‹é¢„æµ‹ - å‡å€¼: {np.mean(model_array):.6f}, æ ‡å‡†å·®: {model_std:.6f}\")\n",
    "                            print(f\"    ä»¿çœŸç»“æœ - å‡å€¼: {np.mean(sim_array):.6f}, æ ‡å‡†å·®: {sim_std:.6f}\")\n",
    "                            \n",
    "                            if model_std > 1e-10 and sim_std > 1e-10:\n",
    "                                model_norm = (model_array - np.mean(model_array)) / model_std\n",
    "                                sim_norm = (sim_array - np.mean(sim_array)) / sim_std\n",
    "                                \n",
    "                                # è®¡ç®—ç›¸å…³ç³»æ•° - ç¡®ä¿è¾“å…¥æ˜¯1ç»´æ•°ç»„\n",
    "                                try:\n",
    "                                    correlation_matrix = np.corrcoef(model_norm, sim_norm)\n",
    "                                    correlation = correlation_matrix[0, 1]\n",
    "                                    \n",
    "                                    # æ£€æŸ¥ç›¸å…³ç³»æ•°æ˜¯å¦æœ‰æ•ˆ\n",
    "                                    if np.isnan(correlation):\n",
    "                                        correlation = 0.0\n",
    "                                        print(f\"  âš  ç›¸å…³ç³»æ•°ä¸ºNaNï¼Œè®¾ç½®ä¸º0\")\n",
    "                                    \n",
    "                                except Exception as corr_e:\n",
    "                                    print(f\"  âš  è®¡ç®—ç›¸å…³ç³»æ•°å¤±è´¥: {corr_e}\")\n",
    "                                    correlation = 0.0\n",
    "                                \n",
    "                                # è®¡ç®—RMSEï¼ˆä½¿ç”¨åŸå§‹æ•°æ®ï¼‰\n",
    "                                rmse = np.sqrt(np.mean((model_array - sim_array)**2))\n",
    "                                \n",
    "                                # è®¡ç®—å¹³å‡ç»å¯¹è¯¯å·®\n",
    "                                mae = np.mean(np.abs(model_array - sim_array))\n",
    "                                \n",
    "                                comparison_results[num_layers] = {\n",
    "                                    'correlation': float(correlation),\n",
    "                                    'rmse': float(rmse),\n",
    "                                    'mae': float(mae),\n",
    "                                    'model_predictions': model_predictions_flat.tolist() if isinstance(model_predictions_flat, np.ndarray) else model_predictions_flat,\n",
    "                                    'simulation_results': sim_detector_responses,\n",
    "                                    'data_length': min_len\n",
    "                                }\n",
    "                                \n",
    "                                print(f\"  âœ… åˆ†æå®Œæˆ:\")\n",
    "                                print(f\"    æ•°æ®é•¿åº¦: {min_len}\")\n",
    "                                print(f\"    ç›¸å…³ç³»æ•°: {correlation:.4f}\")\n",
    "                                print(f\"    RMSE: {rmse:.4f}\")\n",
    "                                print(f\"    MAE: {mae:.4f}\")\n",
    "                                print(f\"    æ¨¡å‹é¢„æµ‹èŒƒå›´: [{np.min(model_array):.4f}, {np.max(model_array):.4f}]\")\n",
    "                                print(f\"    ä»¿çœŸç»“æœèŒƒå›´: [{np.min(sim_array):.4f}, {np.max(sim_array):.4f}]\")\n",
    "                            else:\n",
    "                                print(f\"  âš  æ•°æ®æ ‡å‡†å·®è¿‡å°ï¼Œæ— æ³•è®¡ç®—ç›¸å…³æ€§\")\n",
    "                                print(f\"    æ¨¡å‹æ ‡å‡†å·®: {model_std}\")\n",
    "                                print(f\"    ä»¿çœŸæ ‡å‡†å·®: {sim_std}\")\n",
    "                        else:\n",
    "                            print(f\"  âš  æ•°ç»„é•¿åº¦ä¸åŒ¹é…æˆ–é•¿åº¦ä¸è¶³\")\n",
    "                            print(f\"    æ¨¡å‹æ•°ç»„é•¿åº¦: {len(model_array)}\")\n",
    "                            print(f\"    ä»¿çœŸæ•°ç»„é•¿åº¦: {len(sim_array)}\")\n",
    "                    else:\n",
    "                        print(f\"  âš  æ•°æ®é•¿åº¦ä¸è¶³ (min_len={min_len})ï¼Œæ— æ³•è®¡ç®—ç›¸å…³æ€§\")\n",
    "                else:\n",
    "                    print(f\"  âš  ç¼ºå°‘æœ‰æ•ˆçš„é¢„æµ‹æˆ–ä»¿çœŸæ•°æ®\")\n",
    "                    print(f\"    æ¨¡å‹é¢„æµ‹æœ‰æ•ˆ: {has_model_pred}\")\n",
    "                    print(f\"    ä»¿çœŸç»“æœæœ‰æ•ˆ: {has_sim_results}\")\n",
    "        \n",
    "        # å¯è§†åŒ–å¯¹æ¯”ç»“æœ\n",
    "        if comparison_results:\n",
    "            print(f\"\\nå¯è§†åŒ–æ¨¡å‹-ä»¿çœŸå¯¹æ¯”ç»“æœ...\")\n",
    "            \n",
    "            fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "            \n",
    "            layers_list = sorted(comparison_results.keys())\n",
    "            correlations = [comparison_results[l]['correlation'] for l in layers_list]\n",
    "            rmses = [comparison_results[l]['rmse'] for l in layers_list]\n",
    "            maes = [comparison_results[l]['mae'] for l in layers_list]\n",
    "            \n",
    "            # ç›¸å…³ç³»æ•°å›¾\n",
    "            ax1 = axes[0, 0]\n",
    "            bars1 = ax1.bar(range(len(layers_list)), correlations, alpha=0.7, color='skyblue')\n",
    "            ax1.set_xlabel('å±‚æ•°')\n",
    "            ax1.set_ylabel('ç›¸å…³ç³»æ•°')\n",
    "            ax1.set_title('æ¨¡å‹é¢„æµ‹ä¸ä»¿çœŸç»“æœç›¸å…³æ€§')\n",
    "            ax1.set_xticks(range(len(layers_list)))\n",
    "            ax1.set_xticklabels([f'{l}å±‚' for l in layers_list])\n",
    "            ax1.grid(True, alpha=0.3)\n",
    "            ax1.set_ylim(-1, 1)\n",
    "            ax1.axhline(y=0, color='red', linestyle='--', alpha=0.5)\n",
    "            \n",
    "            # æ·»åŠ æ•°å€¼æ ‡ç­¾\n",
    "            for i, (bar, v) in enumerate(zip(bars1, correlations)):\n",
    "                height = bar.get_height()\n",
    "                ax1.text(bar.get_x() + bar.get_width()/2., height + 0.02 if height >= 0 else height - 0.05,\n",
    "                        f'{v:.3f}', ha='center', va='bottom' if height >= 0 else 'top')\n",
    "            \n",
    "            # RMSEå›¾\n",
    "            ax2 = axes[0, 1]\n",
    "            bars2 = ax2.bar(range(len(layers_list)), rmses, alpha=0.7, color='lightcoral')\n",
    "            ax2.set_xlabel('å±‚æ•°')\n",
    "            ax2.set_ylabel('RMSE')\n",
    "            ax2.set_title('æ¨¡å‹é¢„æµ‹ä¸ä»¿çœŸç»“æœRMSE')\n",
    "            ax2.set_xticks(range(len(layers_list)))\n",
    "            ax2.set_xticklabels([f'{l}å±‚' for l in layers_list])\n",
    "            ax2.grid(True, alpha=0.3)\n",
    "            \n",
    "            # æ·»åŠ æ•°å€¼æ ‡ç­¾\n",
    "            for i, (bar, v) in enumerate(zip(bars2, rmses)):\n",
    "                height = bar.get_height()\n",
    "                if rmses:  # é˜²æ­¢é™¤é›¶é”™è¯¯\n",
    "                    ax2.text(bar.get_x() + bar.get_width()/2., height + max(rmses)*0.01,\n",
    "                            f'{v:.3f}', ha='center', va='bottom')\n",
    "            \n",
    "            # MAEå›¾\n",
    "            ax3 = axes[1, 0]\n",
    "            bars3 = ax3.bar(range(len(layers_list)), maes, alpha=0.7, color='lightgreen')\n",
    "            ax3.set_xlabel('å±‚æ•°')\n",
    "            ax3.set_ylabel('MAE')\n",
    "            ax3.set_title('æ¨¡å‹é¢„æµ‹ä¸ä»¿çœŸç»“æœMAE')\n",
    "            ax3.set_xticks(range(len(layers_list)))\n",
    "            ax3.set_xticklabels([f'{l}å±‚' for l in layers_list])\n",
    "            ax3.grid(True, alpha=0.3)\n",
    "            \n",
    "            # æ·»åŠ æ•°å€¼æ ‡ç­¾\n",
    "            for i, (bar, v) in enumerate(zip(bars3, maes)):\n",
    "                height = bar.get_height()\n",
    "                if maes:  # é˜²æ­¢é™¤é›¶é”™è¯¯\n",
    "                    ax3.text(bar.get_x() + bar.get_width()/2., height + max(maes)*0.01,\n",
    "                            f'{v:.3f}', ha='center', va='bottom')\n",
    "            \n",
    "            # æ•£ç‚¹å›¾ï¼šé€‰æ‹©æœ€ä½³ç›¸å…³æ€§çš„æ¨¡å‹\n",
    "            ax4 = axes[1, 1]\n",
    "            if correlations:\n",
    "                best_idx = np.argmax(np.abs(correlations))  # é€‰æ‹©ç»å¯¹å€¼æœ€å¤§çš„ç›¸å…³ç³»æ•°\n",
    "                best_layer = layers_list[best_idx]\n",
    "                \n",
    "                model_pred = comparison_results[best_layer]['model_predictions']\n",
    "                sim_results_data = comparison_results[best_layer]['simulation_results']\n",
    "                \n",
    "                min_len = min(len(model_pred), len(sim_results_data))\n",
    "                model_array = np.array(model_pred[:min_len])\n",
    "                sim_array = np.array(sim_results_data[:min_len])\n",
    "                \n",
    "                ax4.scatter(model_array, sim_array, alpha=0.7, s=50)\n",
    "                # è®¡ç®—ç†æƒ³åŒ¹é…çº¿çš„èŒƒå›´\n",
    "                all_values = np.concatenate([model_array, sim_array])\n",
    "                min_val, max_val = np.min(all_values), np.max(all_values)\n",
    "                ax4.plot([min_val, max_val], [min_val, max_val], \n",
    "                        'r--', alpha=0.8, label='ç†æƒ³åŒ¹é…çº¿')\n",
    "                \n",
    "                ax4.set_xlabel('æ¨¡å‹é¢„æµ‹å€¼')\n",
    "                ax4.set_ylabel('ä»¿çœŸç»“æœå€¼')\n",
    "                ax4.set_title(f'æœ€ä½³åŒ¹é…æ¨¡å‹æ•£ç‚¹å›¾ ({best_layer}å±‚)\\nr={correlations[best_idx]:.3f}')\n",
    "                ax4.legend()\n",
    "                ax4.grid(True, alpha=0.3)\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f\"{config.save_dir}/model_simulation_comparison.png\", dpi=300)\n",
    "            plt.show()\n",
    "            \n",
    "            # æ‰“å°è¯¦ç»†çš„å¯¹æ¯”åˆ†æç»“æœ\n",
    "            print(f\"\\nğŸ† è¯¦ç»†å¯¹æ¯”åˆ†ææ€»ç»“:\")\n",
    "            print(f\"{'='*50}\")\n",
    "            \n",
    "            if correlations:\n",
    "                best_corr_idx = np.argmax(np.abs(correlations))  # ç»å¯¹å€¼æœ€å¤§\n",
    "                best_rmse_idx = np.argmin(rmses)\n",
    "                best_mae_idx = np.argmin(maes)\n",
    "                \n",
    "                print(f\"æœ€ä½³ç›¸å…³æ€§: {layers_list[best_corr_idx]}å±‚\")\n",
    "                print(f\"  ç›¸å…³ç³»æ•°: {correlations[best_corr_idx]:.4f}\")\n",
    "                print(f\"  æ•°æ®ç‚¹æ•°: {comparison_results[layers_list[best_corr_idx]]['data_length']}\")\n",
    "                \n",
    "                print(f\"\\næœ€ä½RMSE: {layers_list[best_rmse_idx]}å±‚\")\n",
    "                print(f\"  RMSE: {rmses[best_rmse_idx]:.4f}\")\n",
    "                \n",
    "                print(f\"\\næœ€ä½MAE: {layers_list[best_mae_idx]}å±‚\")\n",
    "                print(f\"  MAE: {maes[best_mae_idx]:.4f}\")\n",
    "                \n",
    "                # ä¿å­˜è¯¦ç»†å¯¹æ¯”æ•°æ®\n",
    "                detailed_comparison = {\n",
    "                    'summary': {\n",
    "                        'best_correlation': {\n",
    "                            'layers': int(layers_list[best_corr_idx]), \n",
    "                            'value': float(correlations[best_corr_idx]),\n",
    "                            'data_points': int(comparison_results[layers_list[best_corr_idx]]['data_length'])\n",
    "                        },\n",
    "                        'best_rmse': {\n",
    "                            'layers': int(layers_list[best_rmse_idx]), \n",
    "                            'value': float(rmses[best_rmse_idx])\n",
    "                        },\n",
    "                        'best_mae': {\n",
    "                            'layers': int(layers_list[best_mae_idx]), \n",
    "                            'value': float(maes[best_mae_idx])\n",
    "                        }\n",
    "                    },\n",
    "                    'detailed_results': {}\n",
    "                }\n",
    "                \n",
    "                for layer in layers_list:\n",
    "                    detailed_comparison['detailed_results'][f'{layer}_layers'] = {\n",
    "                        'correlation': float(comparison_results[layer]['correlation']),\n",
    "                        'rmse': float(comparison_results[layer]['rmse']),\n",
    "                        'mae': float(comparison_results[layer]['mae']),\n",
    "                        'data_length': int(comparison_results[layer]['data_length'])\n",
    "                    }\n",
    "                                \n",
    "                import json\n",
    "                with open(f\"{config.save_dir}/detailed_model_simulation_comparison.json\", 'w') as f:\n",
    "                    json.dump(detailed_comparison, f, indent=2)\n",
    "                \n",
    "                print(f\"\\nâœ“ è¯¦ç»†å¯¹æ¯”æ•°æ®å·²ä¿å­˜åˆ°: {config.save_dir}/detailed_model_simulation_comparison.json\")\n",
    "            \n",
    "        else:\n",
    "            print(\"âŒ æ²¡æœ‰æœ‰æ•ˆçš„å¯¹æ¯”ç»“æœ\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ æ¨¡å‹ä¸ä»¿çœŸå¯¹æ¯”åˆ†æå¤±è´¥: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "else:\n",
    "    print(\"è·³è¿‡æ¨¡å‹ä¸ä»¿çœŸå¯¹æ¯”åˆ†æï¼ˆç¼ºå°‘å¿…è¦æ•°æ®ï¼‰\")\n",
    "\n",
    "print(\"âœ“ æ¨¡å‹ä¸ä»¿çœŸå¯¹æ¯”åˆ†æå®Œæˆ\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ODNN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
